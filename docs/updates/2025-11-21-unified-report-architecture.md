# í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì•„í‚¤í…ì²˜ êµ¬ì¶•

**ì‘ì—… ì¼ì**: 2025-11-21
**ì‘ì—…ì**: Development Team
**ê´€ë ¨ ì´ìŠˆ**: DB ë°ì´í„°ì™€ Prediction ë°ì´í„° ë¶„ë¦¬ë¡œ ì¸í•œ ë¦¬í¬íŠ¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°

---

## ğŸ“‹ ëª©ì°¨

1. [ë³€ê²½ ê°œìš”](#ë³€ê²½-ê°œìš”)
2. [AS-IS (ê¸°ì¡´ ìƒíƒœ)](#as-is-ê¸°ì¡´-ìƒíƒœ)
3. [ë³€ê²½ í•„ìš” ì‚¬ìœ ](#ë³€ê²½-í•„ìš”-ì‚¬ìœ )
4. [TO-BE (ë³€ê²½ í›„ ìƒíƒœ)](#to-be-ë³€ê²½-í›„-ìƒíƒœ)
5. [ë³€ê²½ ì‚¬í•­ ìƒì„¸](#ë³€ê²½-ì‚¬í•­-ìƒì„¸)
6. [í…ŒìŠ¤íŠ¸ ê²°ê³¼](#í…ŒìŠ¤íŠ¸-ê²°ê³¼)
7. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
8. [ì°¸ê³  ì‚¬í•­](#ì°¸ê³ -ì‚¬í•­)

---

## ë³€ê²½ ê°œìš”

ê¸°ì¡´ ì‹œìŠ¤í…œì€ DB ê¸°ë°˜ ë¦¬í¬íŠ¸ì™€ Prediction ê¸°ë°˜ ë¦¬í¬íŠ¸ë¥¼ ë³„ë„ë¡œ ìƒì„±í•˜ì—¬ ë°ì´í„° ë¶ˆì¼ì¹˜ ë° ìœ ì§€ë³´ìˆ˜ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ë‹¨ì¼ í†µí•© í•¨ìˆ˜**ë¡œ ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¼ê´€ëœ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì•„í‚¤í…ì²˜ë¡œ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

---

## AS-IS (ê¸°ì¡´ ìƒíƒœ)

### ë¬¸ì œì  1: ë¶„ë¦¬ëœ ë°ì´í„° ìˆ˜ì§‘

```python
# backend/services/stock_analysis_service.py

# âŒ DB ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (Prediction ì œì™¸)
async def generate_stock_report(stock_code: str, db: Session):
    context = await build_analysis_context_from_db(stock_code, db)  # DBë§Œ
    # predictions ë°ì´í„° ì—†ìŒ!
    prompt = build_adaptive_analysis_prompt(context)
    # ...

# âŒ Prediction ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (DB ë°ì´í„° ë¶€ì¡±)
async def update_stock_analysis_summary(stock_code: str, db: Session):
    predictions = db.query(Prediction).filter(...).all()  # Predictionë§Œ
    # ì¬ë¬´ë¹„ìœ¨, íˆ¬ìì ìˆ˜ê¸‰ ë“± DB ë°ì´í„° ë¶€ì¡±!
    prompt = generator._build_prompt(report_data)
    # ...
```

### ë¬¸ì œì  2: í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ì¤‘ë³µ

```python
# âŒ DB ì „ìš© í”„ë¡¬í”„íŠ¸
def build_adaptive_analysis_prompt(context):
    # DB ë°ì´í„°ë§Œ í¬í•¨
    # predictions ì„¹ì…˜ ì—†ìŒ

# âŒ Prediction ì „ìš© í”„ë¡¬í”„íŠ¸
def _build_prompt(report_data):
    # predictions ë°ì´í„°ë§Œ í¬í•¨
    # ì¬ë¬´ë¹„ìœ¨, íˆ¬ìì ìˆ˜ê¸‰ ì„¹ì…˜ ì—†ìŒ
```

### ë¬¸ì œì  3: ì§„ì…ì ë§ˆë‹¤ ë‹¤ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ

```python
# âŒ ì‹ ê·œ ì¢…ëª© ë“±ë¡
reports = await generate_stock_report(stock_code, db)  # DBë§Œ

# âŒ ìŠ¤ì¼€ì¤„ëŸ¬
await update_stock_analysis_summary(stock_code, db)  # Predictionë§Œ

# âŒ Force Update
await update_stock_analysis_summary(stock_code, db)  # Predictionë§Œ
```

### ë¬¸ì œì  4: í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜

```python
# âŒ ë°±ì—”ë“œ: dict í˜•íƒœë¡œ ì €ì¥
data_sources_used = {
    "market_data": True,
    "investor_trading": False,
    ...
}

# âŒ í”„ë¡ íŠ¸ì—”ë“œ: array ê¸°ëŒ€, í‚¤ ì´ë¦„ë„ ë‹¤ë¦„
// Expected: ['stock_prices', 'investor_flow', ...]
dataSources.includes('stock_prices')  // ì˜¤ë¥˜!
```

### ë¬¸ì œì  5: ë‰´ìŠ¤ ì›ë¬¸ ì¤‘ë³µ ì „ì†¡

```python
# âŒ AI ì˜ˆì¸¡ì— ì´ë¯¸ ë‰´ìŠ¤ ë¶„ì„ í¬í•¨ë¨
predictions = {
    "raw_data": [
        {"reasoning": "ì‚¼ì„±ì „ì HBM ì‹ ì œí’ˆ ë°œí‘œë¡œ..."}  # ë‰´ìŠ¤ ìš”ì•½
    ]
}

# âŒ ë‰´ìŠ¤ ì›ë¬¸ë„ ë³„ë„ë¡œ ì „ì†¡ (ì¤‘ë³µ!)
news = {
    "title": "ì‚¼ì„±ì „ì, HBM3E 12H ì–‘ì‚° ë³¸ê²©í™”",  # ì €ì‘ê¶Œ ì´ìŠˆ
    "content": "..."
}
```

### ê²°ê³¼

| ë¬¸ì œ | ì˜í–¥ |
|------|------|
| **ë°ì´í„° ë¶ˆì¼ì¹˜** | ì§„ì…ì ë§ˆë‹¤ ë‹¤ë¥¸ ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ ìƒì„± |
| **ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€** | 2ê°œ í•¨ìˆ˜ë¥¼ ë™ì‹œì— ìˆ˜ì •í•´ì•¼ í•¨ |
| **ë””ë²„ê¹… ë³µì¡ë„** | ë¬¸ì œ ë°œìƒ ì‹œ ì–´ëŠ í•¨ìˆ˜ê°€ ì›ì¸ì¸ì§€ íŒŒì•… ì–´ë ¤ì›€ |
| **í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜** | ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜ë¡œ UI ì„¹ì…˜ ë¯¸í‘œì‹œ |
| **í† í° ë‚­ë¹„** | ì¤‘ë³µ ë°ì´í„° ì „ì†¡ (ë‰´ìŠ¤ ì›ë¬¸ + ì˜ˆì¸¡) |
| **ì €ì‘ê¶Œ ë¦¬ìŠ¤í¬** | ë‰´ìŠ¤ ì›ë¬¸ LLM ì „ì†¡ |

---

## ë³€ê²½ í•„ìš” ì‚¬ìœ 

### 1. ì‚¬ìš©ì í”¼ë“œë°±

> "í”„ë¡ íŠ¸ì—”ë“œì—ì„œ AI ë¦¬í¬íŠ¸ ë³´ë©´ **'ë¶„ì„ ê¸°ì¤€: 0ê±´ì˜ ì˜ˆì¸¡'**ì´ë¼ê³  ë‚˜ì˜¤ëŠ”ë°, ì‹¤ì œë¡œëŠ” ì˜ˆì¸¡ì´ ìˆì–´ìš”!"

**ì›ì¸ ë¶„ì„**:
- DB ê¸°ë°˜ ë¦¬í¬íŠ¸(`generate_stock_report`)ê°€ í˜¸ì¶œë¨
- Prediction ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•„ `based_on_prediction_count=0`
- í”„ë¡ íŠ¸ì—”ë“œì— ì˜ëª»ëœ ì •ë³´ í‘œì‹œ

### 2. ê°œë°œì ìš”êµ¬ì‚¬í•­

> "**ê·¼ë³¸ì ìœ¼ë¡œ ê°œì„ **í•´ì•¼ í•´. í•˜ë‚˜ì˜ í•¨ìˆ˜ë¡œ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë°›ê²Œ í–ˆì–´ì•¼ í•˜ëŠ” ê±° ì•„ëƒ?"

**ë¬¸ì œì **:
```python
# âŒ ì–´ë””ì„œ í˜¸ì¶œí•˜ëƒì— ë”°ë¼ ë‹¤ë¥¸ ê²°ê³¼
trigger_initial_analysis()  # â†’ generate_stock_report() â†’ predictions ì—†ìŒ
scheduler()                  # â†’ update_stock_analysis_summary() â†’ DB ë°ì´í„° ë¶€ì¡±
force_update()              # â†’ update_stock_analysis_summary() â†’ DB ë°ì´í„° ë¶€ì¡±
```

### 3. ê¸°ìˆ ì  ë¶€ì±„

```python
# âŒ 436ì¤„ì˜ ì¤‘ë³µ ì½”ë“œ
- generate_stock_report(): 187ì¤„
- generate_db_based_report(): 8ì¤„
- update_stock_analysis_summary(): 241ì¤„

# âŒ 2ê°œì˜ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
- build_adaptive_analysis_prompt()  # DBìš©
- _build_prompt()                    # Predictionìš©
```

---

## TO-BE (ë³€ê²½ í›„ ìƒíƒœ)

### í•µì‹¬ ì•„í‚¤í…ì²˜: ë‹¨ì¼ í†µí•© í•¨ìˆ˜

```python
# âœ… í†µí•© ë¦¬í¬íŠ¸ ìƒì„± (ìœ ì¼í•œ ì§„ì…ì )
async def generate_unified_stock_report(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> List[StockAnalysisSummary]:
    """
    í†µí•© ì¢…ëª© ë¦¬í¬íŠ¸ ìƒì„± - DB + Prediction í†µí•©, ì „ì²´ ëª¨ë¸ ì§€ì›

    ëª¨ë“  ì§„ì…ì ì´ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥
    """
    # 1. í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• (DB + Predictions)
    context = await build_unified_context(stock_code, db)

    # 2. ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    data_sources = context.get("data_sources", {})

    # 3. í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = build_unified_prompt(context)

    # 4. ëª¨ë“  í™œì„± ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰
    tasks = [generate_for_single_model(model) for model in active_models]
    results = await asyncio.gather(*tasks)

    # 5. ê²°ê³¼ ì €ì¥ ë° ë°˜í™˜
    return created_summaries
```

### í†µí•© ë°ì´í„° ìˆ˜ì§‘

```python
# âœ… DB + Prediction í†µí•© ìˆ˜ì§‘
async def build_unified_context(stock_code: str, db: Session) -> Dict[str, Any]:
    """
    í†µí•© ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± - DB ë°ì´í„° + Prediction ë°ì´í„°
    """
    # 1. DB ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    context = await build_analysis_context_from_db(stock_code, db)

    # 2. Prediction ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ (ìµœê·¼ 7ì¼)
    seven_days_ago = datetime.now() - timedelta(days=7)
    predictions = db.query(Prediction).filter(
        Prediction.stock_code == stock_code,
        Prediction.created_at >= seven_days_ago
    ).all()

    if predictions:
        context["predictions"] = {
            "raw_data": [...],  # ìƒìœ„ 20ê°œ
            "statistics": {
                "total": 109,
                "positive": 58,
                "negative": 22,
                # ...
            }
        }
        context["data_sources"]["predictions"] = True

    return context
```

### í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±

```python
# âœ… ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± (ë™ì  ì„¹ì…˜)
def build_unified_prompt(context: Dict[str, Any]) -> str:
    """
    í†µí•© ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±

    ê°€ìš© ë°ì´í„°ì— ë”°ë¼ ì„¹ì…˜ ë™ì  ìƒì„±:
    - ì£¼ê°€Â·ê±°ë˜ëŸ‰
    - íˆ¬ìì ìˆ˜ê¸‰
    - ì¬ë¬´ë¹„ìœ¨
    - ìƒí’ˆì •ë³´
    - ê¸°ìˆ ì  ì§€í‘œ
    - AI ì˜ˆì¸¡ ë¶„ì„ (ì‹ ê·œ ì¶”ê°€!) â­
    """
    data_sources = context.get("data_sources", {})

    # ... ê¸°ì¡´ ì„¹ì…˜ë“¤

    # âœ… AI ì˜ˆì¸¡ ì„¹ì…˜ (predictions ìˆì„ ë•Œë§Œ)
    if data_sources.get("predictions"):
        prompt += f"""
### ğŸ¤– AI ì˜ˆì¸¡ ë¶„ì„ (ìµœê·¼ 7ì¼)
- ì´ ì˜ˆì¸¡ ê±´ìˆ˜: {total}ê±´
- ê°ì„± ë¶„í¬: ê¸ì • {positive}ê±´ | ë¶€ì • {negative}ê±´
- ê³ ì˜í–¥ ì˜ˆì¸¡: {high_impact}ê±´

**ì£¼ìš” ì˜ˆì¸¡ ìƒ˜í”Œ (ìµœê·¼ 5ê±´)**:
1. ğŸ“ˆ POSITIVE (high): {reasoning}...
"""

    return prompt
```

### ëª¨ë“  ì§„ì…ì  í†µí•©

```python
# âœ… ëª¨ë“  ê³³ì—ì„œ ë™ì¼í•œ í•¨ìˆ˜ í˜¸ì¶œ
from backend.services.stock_analysis_service import generate_unified_stock_report

# ì‹ ê·œ ì¢…ëª© ë“±ë¡
async def trigger_initial_analysis(stock_code: str, db: Session):
    reports = await generate_unified_stock_report(stock_code, db)

# ìŠ¤ì¼€ì¤„ëŸ¬
async def _generate_stock_reports(self):
    reports = await generate_unified_stock_report(stock_code, db, force_update=True)

# Force Update
async def _generate_report_background(stock_code: str, db: Session):
    reports = await generate_unified_stock_report(stock_code, db, force_update=True)
```

### í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° í˜•ì‹ ìˆ˜ì •

```python
# âœ… ë°±ì—”ë“œ: dict â†’ array ë³€í™˜ + í‚¤ ë§¤í•‘
def _format_summary_output(summary, model_map):
    # ë°±ì—”ë“œ â†’ í”„ë¡ íŠ¸ì—”ë“œ í‚¤ ë§¤í•‘
    backend_to_frontend_keys = {
        "market_data": "stock_prices",
        "investor_trading": "investor_flow",
        "financial_ratios": "financial_metrics",
        "product_info": "company_info",
        "technical_indicators": "technical_indicators",
        "news": "market_trends",
        "predictions": None,  # í”„ë¡ íŠ¸ì—”ë“œ ë¯¸í‘œì‹œ
    }

    # dict â†’ array ë³€í™˜ (Trueì¸ ê°’ë§Œ)
    data_sources_array = []
    if isinstance(data_sources_used, dict):
        for backend_key, is_used in data_sources_used.items():
            if is_used:
                frontend_key = backend_to_frontend_keys[backend_key]
                if frontend_key:
                    data_sources_array.append(frontend_key)

    return {
        "data_sources_used": data_sources_array,  # âœ… ë°°ì—´ í˜•íƒœ
        # ...
    }
```

```typescript
// âœ… í”„ë¡ íŠ¸ì—”ë“œ: ì •ìƒ ë™ì‘
const dataSources = ['stock_prices', 'investor_flow', ...];
dataSources.includes('stock_prices')  // âœ… true
```

### ë°ì´í„° ìµœì í™”

```python
# âœ… ì˜ˆì¸¡ ê¸°ê°„ ë‹¨ì¶• (30ì¼ â†’ 7ì¼)
seven_days_ago = datetime.now() - timedelta(days=7)  # ë³€ê²½
predictions = db.query(Prediction).filter(
    Prediction.created_at >= seven_days_ago
).all()

# ê²°ê³¼: 459ê±´ â†’ 109ê±´ (77% ê°ì†Œ)
```

```python
# âœ… ë‰´ìŠ¤ ì›ë¬¸ ì œê±° (ì¤‘ë³µ + ì €ì‘ê¶Œ)
# ì´ì „: ë‰´ìŠ¤ ì„¹ì…˜ í¬í•¨
if data_sources.get("news"):
    prompt += f"### ğŸ“° ìµœê·¼ ì‹œì¥ ë™í–¥\n{news_title}..."  # âŒ ì œê±°ë¨

# ì´í›„: AI ì˜ˆì¸¡ë§Œ ì „ì†¡ (ë‰´ìŠ¤ëŠ” reasoningì— ìš”ì•½ë¨)
if data_sources.get("predictions"):
    prompt += f"### ğŸ¤– AI ì˜ˆì¸¡ ë¶„ì„\n{reasoning}..."  # âœ… ìœ ì§€
```

### A/B í…ŒìŠ¤íŠ¸ UI ê°œì„ 

```typescript
// âœ… A/B í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œë„ ì „ì²´ ì„¹ì…˜ í‘œì‹œ
const renderModelSummary = (summary, modelName, bgClass, borderClass) => (
  <div>
    {/* ì‹ ë¢°ë„ */}
    {summary.confidence_level && <div>...</div>}

    {/* âœ… ë°ì´í„° ì†ŒìŠ¤ ë°°ì§€ */}
    {summary.data_sources_used && <DataSourceBadges />}

    {/* âœ… ì œí•œì‚¬í•­ */}
    {summary.limitations && <div>...</div>}

    {/* âœ… ì¢…í•© ì˜ê²¬ (ë°•ìŠ¤ ì¶”ê°€) */}
    {summary.overall_summary && (
      <div className="bg-white rounded p-3 border-l-4 border-indigo-400">
        <p>{summary.overall_summary}</p>
      </div>
    )}

    {/* âœ… ê¸°ê°„ë³„ ì „ëµ */}
    {summary.short_term_scenario && <div>...</div>}

    {/* âœ… ë¦¬ìŠ¤í¬ & ê¸°íšŒ */}
    {summary.risk_factors && <div>...</div>}

    {/* âœ… ìµœì¢… ì¶”ì²œ (ë°•ìŠ¤ ì¶”ê°€) */}
    {summary.recommendation && (
      <div className="bg-white rounded p-3 border-l-4 border-purple-400">
        <p>{summary.recommendation}</p>
      </div>
    )}
  </div>
);
```

---

## ë³€ê²½ ì‚¬í•­ ìƒì„¸

### 1. í†µí•© í•¨ìˆ˜ êµ¬ì¶•

**íŒŒì¼**: `backend/services/stock_analysis_service.py`

#### ì‹ ê·œ í•¨ìˆ˜: `generate_unified_stock_report()`

```python
async def generate_unified_stock_report(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> List[StockAnalysisSummary]:
    """
    í†µí•© ì¢…ëª© ë¦¬í¬íŠ¸ ìƒì„± - DB + Prediction í†µí•©, ì „ì²´ ëª¨ë¸ ì§€ì›

    ë³€ê²½ ì‚¬í•­:
    - DB ë°ì´í„° + Prediction ë°ì´í„° í†µí•© ìˆ˜ì§‘
    - ë°ì´í„° ê°€ìš©ì„±ì— ë”°ë¥¸ ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ëª¨ë“  í™œì„± ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰
    - ë©”íƒ€ë°ì´í„° í¬í•¨ (data_sources_used, limitations, confidence_level)
    """
    logger.info(f"ğŸ“Š Unified report generation for {stock_code}")

    try:
        # 1. í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
        context = await build_unified_context(stock_code, db)

        # 2. ë°ì´í„° ê°€ìš©ì„± í™•ì¸
        data_sources = context.get("data_sources", {})
        available_count = sum(1 for v in data_sources.values() if v)

        logger.info(f"  ğŸ“Š Data sources: {available_count}/8 available")
        logger.info(f"     {', '.join(k for k, v in data_sources.items() if v)}")

        # 3. í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±
        from backend.llm.investment_report import build_unified_prompt
        prompt = build_unified_prompt(context)

        # 4. ëª¨ë“  í™œì„± ëª¨ë¸ ì¡°íšŒ
        active_models = db.query(Model).filter(Model.is_active == True).all()

        # 5. Prediction í†µê³„ ê³„ì‚°
        predictions_data = context.get("predictions", {})
        stats = predictions_data.get("statistics", {})
        total_predictions = stats.get("total", 0)
        up_count = stats.get("positive", 0)
        down_count = stats.get("negative", 0)
        hold_count = stats.get("neutral", 0)

        # 6. ê° ëª¨ë¸ë³„ë¡œ ë³‘ë ¬ ë¦¬í¬íŠ¸ ìƒì„±
        async def generate_for_single_model(model: Model):
            # ... LLM í˜¸ì¶œ ë° ê²°ê³¼ ì €ì¥

            summary = StockAnalysisSummary(
                stock_code=stock_code,
                model_id=model.id,
                # ... ê¸°ë³¸ í•„ë“œ
                confidence_level=report_data.get("confidence_level", "medium"),
                data_sources_used=data_sources,  # âœ… í†µí•© data_sources
                limitations=report_data.get("limitations", []),
                data_completeness_score=available_count / 8.0,  # 8ê°œ ì†ŒìŠ¤
                total_predictions=total_predictions,  # âœ… Prediction í†µê³„
                based_on_prediction_count=total_predictions,
                up_count=up_count,
                down_count=down_count,
                hold_count=hold_count,
            )

            return {"success": True, "model": model, "summary": summary}

        # 7. ë³‘ë ¬ ì‹¤í–‰
        logger.info(f"  ğŸš€ Starting parallel report generation for {len(active_models)} models")
        tasks = [generate_for_single_model(model) for model in active_models]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # 8. ê²°ê³¼ ì²˜ë¦¬ ë° ì €ì¥
        # ...

        logger.info(f"âœ… Unified report generation complete: {len(created_summaries)}/{len(active_models)} models succeeded")
        return created_summaries

    except Exception as e:
        logger.error(f"âŒ Unified report generation failed for {stock_code}: {e}", exc_info=True)
        return []
```

#### ì‹ ê·œ í•¨ìˆ˜: `build_unified_context()`

```python
async def build_unified_context(stock_code: str, db: Session) -> Dict[str, Any]:
    """
    í†µí•© ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± - DB ë°ì´í„° + Prediction ë°ì´í„°

    ë³€ê²½ ì‚¬í•­:
    - DB ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    - Prediction ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ (ìµœê·¼ 7ì¼)
    - í†µí•© data_sources í”Œë˜ê·¸
    """
    logger.info(f"ğŸ”„ Building unified context for {stock_code}")

    # 1. DB ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)
    context = await build_analysis_context_from_db(stock_code, db)

    # 2. Prediction ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ (ìµœê·¼ 7ì¼)
    seven_days_ago = datetime.now() - timedelta(days=7)
    predictions = (
        db.query(Prediction)
        .filter(
            Prediction.stock_code == stock_code,
            Prediction.created_at >= seven_days_ago
        )
        .order_by(Prediction.created_at.desc())
        .all()
    )

    if predictions:
        # í†µê³„ ê³„ì‚°
        total = len(predictions)
        positive_count = sum(1 for p in predictions if p.sentiment_direction == "positive")
        negative_count = sum(1 for p in predictions if p.sentiment_direction == "negative")
        neutral_count = sum(1 for p in predictions if p.sentiment_direction == "neutral")
        high_impact_count = sum(1 for p in predictions if p.impact_level == "high")

        # í‰ê·  ì ìˆ˜
        sentiment_scores = [p.sentiment_score for p in predictions if p.sentiment_score is not None]
        relevance_scores = [p.relevance_score for p in predictions if p.relevance_score is not None]

        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0

        context["predictions"] = {
            "raw_data": [
                {
                    "sentiment_direction": p.sentiment_direction,
                    "sentiment_score": p.sentiment_score,
                    "impact_level": p.impact_level,
                    "relevance_score": p.relevance_score,
                    "reasoning": p.reasoning,
                    "created_at": p.created_at.isoformat() if p.created_at else None,
                }
                for p in predictions[:20]  # ìƒìœ„ 20ê°œë§Œ
            ],
            "statistics": {
                "total": total,
                "positive": positive_count,
                "negative": negative_count,
                "neutral": neutral_count,
                "high_impact": high_impact_count,
                "avg_sentiment": round(avg_sentiment, 2),
                "avg_relevance": round(avg_relevance, 2),
            }
        }
        context["data_sources"]["predictions"] = True

        logger.info(f"  âœ… Predictions: {total}ê±´ (ê¸ì • {positive_count}, ë¶€ì • {negative_count}, ì¤‘ë¦½ {neutral_count})")

    return context
```

### 2. í”„ë¡¬í”„íŠ¸ ìƒì„± í†µí•©

**íŒŒì¼**: `backend/llm/investment_report.py`

#### ì‹ ê·œ í•¨ìˆ˜: `build_unified_prompt()`

```python
def build_unified_prompt(context: Dict[str, Any]) -> str:
    """
    í†µí•© ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± (DB + Prediction)

    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´ ì„¹ì…˜ ìœ ì§€ (ì£¼ê°€, ìˆ˜ê¸‰, ì¬ë¬´, ìƒí’ˆ, ê¸°ìˆ ì§€í‘œ)
    - AI ì˜ˆì¸¡ ì„¹ì…˜ ì¶”ê°€ (predictions ìˆì„ ë•Œë§Œ)
    - ë‰´ìŠ¤ ì›ë¬¸ ì„¹ì…˜ ì œê±° (ì¤‘ë³µ + ì €ì‘ê¶Œ)
    """
    data_sources = context.get("data_sources", {})

    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

# ì¢…ëª© ë¶„ì„ ë°ì´í„°

## ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤
{', '.join(k for k, v in data_sources.items() if v)}

---
"""

    # 1. ì£¼ê°€Â·ê±°ë˜ëŸ‰ (ìµœê·¼ 5ì¼)
    if data_sources.get("market_data"):
        # ...

    # 2. íˆ¬ìì ìˆ˜ê¸‰ (ìµœê·¼ 5ì¼)
    if data_sources.get("investor_trading"):
        # ...

    # 3. ì¬ë¬´ë¹„ìœ¨ (ìµœê·¼ 3ê°œ ë¶„ê¸°)
    if data_sources.get("financial_ratios"):
        # ...

    # 4. ìƒí’ˆì •ë³´
    if data_sources.get("product_info"):
        # ...

    # 5. ê¸°ìˆ ì  ì§€í‘œ
    if data_sources.get("technical_indicators"):
        # ...

    # âœ… 6. AI ì˜ˆì¸¡ ë¶„ì„ (ì‹ ê·œ ì¶”ê°€!)
    if data_sources.get("predictions"):
        predictions_data = context.get("predictions", {})
        stats = predictions_data.get("statistics", {})

        total = stats.get("total", 0)
        positive = stats.get("positive", 0)
        negative = stats.get("negative", 0)
        neutral = stats.get("neutral", 0)
        high_impact = stats.get("high_impact", 0)
        avg_sentiment = stats.get("avg_sentiment", 0)
        avg_relevance = stats.get("avg_relevance", 0)

        positive_pct = (positive / total * 100) if total > 0 else 0
        negative_pct = (negative / total * 100) if total > 0 else 0

        prompt += f"""
### ğŸ¤– AI ì˜ˆì¸¡ ë¶„ì„ (ìµœê·¼ 7ì¼)
- **ì´ ì˜ˆì¸¡ ê±´ìˆ˜**: {total}ê±´
- **ê°ì„± ë¶„í¬**: ê¸ì • {positive}ê±´ ({positive_pct:.1f}%) | ë¶€ì • {negative}ê±´ ({negative_pct:.1f}%) | ì¤‘ë¦½ {neutral}ê±´
- **ê³ ì˜í–¥ ì˜ˆì¸¡**: {high_impact}ê±´
- **í‰ê·  ê°ì„± ì ìˆ˜**: {avg_sentiment:.2f} (-1.0 ~ +1.0)
- **í‰ê·  ê´€ë ¨ì„±**: {avg_relevance:.2f}

"""
        # ì£¼ìš” ì˜ˆì¸¡ ìƒ˜í”Œ (ìµœê·¼ 5ê±´)
        raw_data = predictions_data.get("raw_data", [])
        if raw_data:
            prompt += "**ì£¼ìš” ì˜ˆì¸¡ ìƒ˜í”Œ (ìµœê·¼ 5ê±´)**:\n"
            for idx, pred in enumerate(raw_data[:5], 1):
                reasoning = pred.get('reasoning', 'N/A')
                direction = pred.get('sentiment_direction', 'N/A')
                impact = pred.get('impact_level', 'N/A')
                direction_emoji = "ğŸ“ˆ" if direction == "positive" else "ğŸ“‰" if direction == "negative" else "â¡ï¸"
                prompt += f"{idx}. {direction_emoji} {direction.upper()} ({impact}): {reasoning[:100]}...\n"

    # âŒ ë‰´ìŠ¤ ì›ë¬¸ ì„¹ì…˜ ì œê±°ë¨ (ì´ì „ ì½”ë“œ ì‚­ì œ)

    # JSON ì‘ë‹µ í˜•ì‹ ìš”êµ¬
    prompt += """
---

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

```json
{
  "overall_summary": "ì¢…í•© ì˜ê²¬ (2-3ë¬¸ì¥)",
  "short_term_scenario": "ë‹¨ê¸° ì „ëµ (1ì¼~1ì£¼)",
  "medium_term_scenario": "ì¤‘ê¸° ì „ëµ (1ì£¼~1ê°œì›”)",
  "long_term_scenario": "ì¥ê¸° ì „ëµ (1ê°œì›” ì´ìƒ)",
  "risk_factors": ["ë¦¬ìŠ¤í¬ ìš”ì¸ 1", "ë¦¬ìŠ¤í¬ ìš”ì¸ 2"],
  "opportunity_factors": ["ê¸°íšŒ ìš”ì¸ 1", "ê¸°íšŒ ìš”ì¸ 2"],
  "recommendation": "ìµœì¢… ì¶”ì²œ (ëª…í™•í•œ ì•¡ì…˜ + ì´ìœ )",
  "confidence_level": "high/medium/low ì¤‘ í•˜ë‚˜",
  "limitations": ["ë¶„ì„ í•œê³„ì  1", "í•œê³„ì  2"]
}
```
"""

    return prompt
```

### 3. ì§„ì…ì  í†µí•©

#### ì‹ ê·œ ì¢…ëª© ë“±ë¡

**íŒŒì¼**: `backend/services/stock_analysis_service.py`

```python
async def trigger_initial_analysis(stock_code: str, db: Session):
    """ì‹ ê·œ ì¢…ëª© ë“±ë¡ ì‹œ ì´ˆê¸° ë¶„ì„"""
    try:
        logger.info(f"ğŸ”„ Triggering initial analysis for {stock_code}")

        # âœ… í†µí•© í•¨ìˆ˜ í˜¸ì¶œ
        reports = await generate_unified_stock_report(stock_code, db)

        if not reports:
            await create_placeholder_report(...)
            return

        logger.info(f"âœ… Initial analysis completed for {stock_code}: {len(reports)} reports generated")

    except Exception as e:
        logger.error(f"âŒ Initial analysis failed for {stock_code}: {e}")
        await create_placeholder_report(stock_code, db, error_msg=str(e))
```

#### ìŠ¤ì¼€ì¤„ëŸ¬

**íŒŒì¼**: `backend/scheduler/crawler_scheduler.py`

```python
async def _generate_stock_reports(self) -> None:
    """ì£¼ê¸°ì  ë¦¬í¬íŠ¸ ìƒì„±"""
    db = SessionLocal()

    try:
        from backend.services.stock_analysis_service import generate_unified_stock_report

        # í™œì„± ì¢…ëª© ì¡°íšŒ
        from backend.db.models.stock import Stock
        active_stocks = db.query(Stock).filter(Stock.is_active == True).all()

        logger.info(f"ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘: {len(active_stocks)}ê°œ ì¢…ëª©")

        for stock in active_stocks:
            try:
                # âœ… í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
                logger.info(f"  ğŸ“Š {stock.name} ({stock.code}): í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")

                reports = await generate_unified_stock_report(
                    stock_code=stock.code,
                    db=db,
                    force_update=True
                )

                if reports:
                    logger.info(f"  âœ… {stock.name}: {len(reports)}ê°œ ëª¨ë¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
                else:
                    logger.warning(f"  âš ï¸ {stock.name}: ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")

            except Exception as e:
                logger.error(f"  âŒ {stock.name} ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)

    finally:
        db.close()
```

#### Force Update

**íŒŒì¼**: `backend/api/dashboard.py`

```python
async def _generate_report_background(stock_code: str, stock_name: str, db: Session):
    """ë°±ê·¸ë¼ìš´ë“œ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        from backend.services.stock_analysis_service import generate_unified_stock_report

        logger.info(f"ğŸ”„ [{stock_code}] {stock_name} ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")

        # âœ… í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
        reports = await generate_unified_stock_report(stock_code, db, force_update=True)

        if reports:
            report_generation_status[stock_code] = {
                "status": "completed",
                "completed_at": datetime.now(),
                "stock_name": stock_name,
                "model_count": len(reports)
            }
            logger.info(f"âœ… [{stock_code}] {stock_name} í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ({len(reports)}ê°œ ëª¨ë¸)")
        else:
            report_generation_status[stock_code] = {
                "status": "failed",
                "error": "No reports generated"
            }

    except Exception as e:
        logger.error(f"âŒ [{stock_code}] ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        report_generation_status[stock_code] = {
            "status": "failed",
            "error": str(e)
        }
    finally:
        db.close()
```

### 4. í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì •

#### ë°ì´í„° í˜•ì‹ ë³€í™˜

**íŒŒì¼**: `backend/services/stock_analysis_service.py`

```python
def _format_summary_output(
    summary: StockAnalysisSummary,
    model_map: Dict[int, Model],
) -> Dict[str, Any]:
    """StockAnalysisSummary ì—”í‹°í‹°ë¥¼ API ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜"""

    # ... ê¸°ì¡´ ì½”ë“œ

    # âœ… ë°ì´í„° ì†ŒìŠ¤ íŒŒì‹± ë° ë³€í™˜
    data_sources_used = summary.data_sources_used
    if isinstance(data_sources_used, str):
        try:
            data_sources_used = json.loads(data_sources_used)
        except:
            data_sources_used = None

    # âœ… ë°±ì—”ë“œ â†’ í”„ë¡ íŠ¸ì—”ë“œ í‚¤ ë§¤í•‘ ë° ë°°ì—´ ë³€í™˜
    backend_to_frontend_keys = {
        "market_data": "stock_prices",
        "investor_trading": "investor_flow",
        "financial_ratios": "financial_metrics",
        "product_info": "company_info",
        "technical_indicators": "technical_indicators",
        "news": "market_trends",
        "predictions": None,  # í”„ë¡ íŠ¸ì—”ë“œì— í‘œì‹œ ì•ˆí•¨
    }

    # dict -> array ë³€í™˜ (Trueì¸ ê°’ë§Œ ì¶”ì¶œí•˜ê³  í”„ë¡ íŠ¸ì—”ë“œ í‚¤ë¡œ ë§¤í•‘)
    data_sources_array = []
    if isinstance(data_sources_used, dict):
        for backend_key, is_used in data_sources_used.items():
            if is_used and backend_key in backend_to_frontend_keys:
                frontend_key = backend_to_frontend_keys[backend_key]
                if frontend_key:  # Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                    data_sources_array.append(frontend_key)
        data_sources_used = data_sources_array

    return {
        "model_id": summary.model_id,
        "model_name": model_info.name if model_info else None,
        # ...
        "data_sources_used": data_sources_used,  # âœ… ì´ì œ ë°°ì—´ í˜•íƒœ
        # ...
    }
```

#### A/B í…ŒìŠ¤íŠ¸ UI ê°œì„ 

**íŒŒì¼**: `frontend/app/components/StockDetailView.tsx`

```typescript
// âœ… renderModelSummary() í•¨ìˆ˜ ê°œì„ 
const renderModelSummary = (
  summary: AnalysisSummary,
  modelName: string,
  bgClass: string,
  borderClass: string
) => (
  <div className={`flex-1 p-6 rounded-xl border-2 ${bgClass} ${borderClass}`}>
    <h3 className="text-lg font-bold mb-4 text-gray-800">{modelName}</h3>

    {/* ì‹ ë¢°ë„ */}
    {summary.confidence_level && <div>...</div>}

    {/* âœ… ë°ì´í„° ì†ŒìŠ¤ ë°°ì§€ (ì¶”ê°€) */}
    {summary.data_sources_used && (
      <div className="mb-4">
        <h4 className="text-xs font-bold text-gray-700 mb-2">ì‚¬ìš©ëœ ë°ì´í„°:</h4>
        <DataSourceBadges dataSources={summary.data_sources_used} />
      </div>
    )}

    {/* âœ… ì œí•œì‚¬í•­ (ì¶”ê°€) */}
    {summary.limitations && summary.limitations.length > 0 && (
      <div className="mb-4 bg-yellow-50 border-l-2 border-yellow-400 p-3 rounded">
        <h4 className="text-xs font-bold text-yellow-800 mb-2">âš ï¸ ì œí•œì‚¬í•­</h4>
        <ul className="space-y-1">
          {summary.limitations.map((limitation, idx) => (
            <li key={idx} className="text-xs text-yellow-700">â€¢ {limitation}</li>
          ))}
        </ul>
      </div>
    )}

    {/* âœ… ì¢…í•© ì˜ê²¬ (ë°•ìŠ¤ ì¶”ê°€) */}
    {summary.overall_summary && (
      <div className="mb-4">
        <h4 className="text-sm font-bold text-gray-700 mb-2">ğŸ“‹ ì¢…í•© ì˜ê²¬</h4>
        <div className="bg-white rounded p-3 border-l-4 border-indigo-400">
          <p className="text-sm text-gray-700">{summary.overall_summary}</p>
        </div>
      </div>
    )}

    {/* âœ… ê¸°ê°„ë³„ ì „ëµ (ì¶”ê°€) */}
    {(summary.short_term_scenario || summary.medium_term_scenario || summary.long_term_scenario) && (
      <div className="mb-4">
        <h4 className="text-sm font-bold text-gray-700 mb-2">ğŸ“… ê¸°ê°„ë³„ ì „ëµ</h4>
        <div className="space-y-2">
          {summary.short_term_scenario && (
            <div className="bg-white rounded p-2 border-l-2 border-red-400">
              <h5 className="text-xs font-bold text-red-700">ğŸ”¹ ë‹¨ê¸°</h5>
              <p className="text-xs text-gray-700">{summary.short_term_scenario}</p>
            </div>
          )}
          {/* ì¤‘ê¸°, ì¥ê¸° ë™ì¼... */}
        </div>
      </div>
    )}

    {/* âœ… ë¦¬ìŠ¤í¬ & ê¸°íšŒ (ì¶”ê°€) */}
    {(summary.risk_factors?.length > 0 || summary.opportunity_factors?.length > 0) && (
      <div className="mb-4">
        <h4 className="text-sm font-bold text-gray-700 mb-2">âš–ï¸ ë¦¬ìŠ¤í¬ & ê¸°íšŒ</h4>
        {/* ... */}
      </div>
    )}

    {/* âœ… ìµœì¢… ì¶”ì²œ (ë°•ìŠ¤ ì¶”ê°€) */}
    {summary.recommendation && (
      <div className="mb-2">
        <h4 className="text-sm font-bold text-gray-700 mb-2">ğŸ¯ ìµœì¢… ì¶”ì²œ</h4>
        <div className="bg-white rounded p-3 border-l-4 border-purple-400">
          <p className="text-sm text-gray-700 font-medium">{summary.recommendation}</p>
        </div>
      </div>
    )}
  </div>
);
```

### 5. Deprecated ì½”ë“œ ì œê±°

**íŒŒì¼**: `backend/services/stock_analysis_service.py`

#### ì œê±°ëœ í•¨ìˆ˜ (ì´ 436ì¤„)

```python
# âŒ ì œê±°ë¨ (187ì¤„)
async def generate_stock_report(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> List[StockAnalysisSummary]:
    """DB ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (DEPRECATED)"""
    # ...

# âŒ ì œê±°ë¨ (8ì¤„)
async def generate_db_based_report(
    stock_code: str,
    db: Session
) -> Optional[StockAnalysisSummary]:
    """[DEPRECATED] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€"""
    # ...

# âŒ ì œê±°ë¨ (241ì¤„)
async def update_stock_analysis_summary(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> Optional[StockAnalysisSummary]:
    """Prediction ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (DEPRECATED)"""
    # ...
```

**íŒŒì¼**: `backend/api/stocks.py`

```python
# âŒ ì œê±°ë¨ (ë¯¸ì‚¬ìš© import)
from backend.services.stock_analysis_service import (
    get_stock_analysis_summary,
    update_stock_analysis_summary,  # âŒ ì œê±°
)
```

### 6. ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ 

**íŒŒì¼**: `backend/services/stock_analysis_service.py`

```python
# âœ… JSON íŒŒì‹± ì—ëŸ¬ ê°œì„ 
async def generate_for_single_model(model: Model):
    # ...

    # âœ… ë””ë²„ê¹…: ì‘ë‹µ ë‚´ìš© ê²€ì¦ ë° ë¡œê¹…
    if not result_text or not result_text.strip():
        logger.error(f"  âŒ {model.name}: Empty response received")
        raise ValueError(f"Empty response from {model.name}")

    logger.debug(f"  ğŸ“ {model.name} response (first 200 chars): {result_text[:200]}")

    # âœ… JSON íŒŒì‹± with ì—ëŸ¬ ë¡œê¹…
    try:
        report_data = json.loads(result_text)
    except json.JSONDecodeError as e:
        logger.error(f"  âŒ {model.name} JSON parse error. Response: {result_text[:500]}")
        raise
```

---

## í…ŒìŠ¤íŠ¸ ê²°ê³¼

### 1. í†µí•© ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸

```bash
# ì‚¼ì„±ì „ì (005930) ë¦¬í¬íŠ¸ ìƒì„±
ğŸ“Š Unified report generation for 005930
  ğŸ“Š Data sources: 7/8 available
     market_data, investor_trading, financial_ratios, product_info, technical_indicators, news, predictions
  ğŸš€ Starting parallel report generation for 4 models
  âœ… GPT-4o report created (confidence=medium, predictions=109)
  âœ… Qwen3 Max report created (confidence=medium, predictions=109)
  âœ… DeepSeek V3.2 report created (confidence=medium, predictions=109)
  âœ… gpt-5-mini report created (confidence=medium, predictions=109)
  ğŸ’¾ GPT-4o report saved to DB
  ğŸ’¾ Qwen3 Max report saved to DB
  ğŸ’¾ DeepSeek V3.2 report saved to DB
  ğŸ’¾ gpt-5-mini report saved to DB
âœ… Unified report generation complete: 4/4 models succeeded
```

### 2. ë°ì´í„° ê²€ì¦

| í•­ëª© | ì´ì „ (30ì¼) | ì´í›„ (7ì¼) | ë³€í™” |
|------|------------|-----------|------|
| **ì˜ˆì¸¡ ê±´ìˆ˜** | 459ê±´ | 109ê±´ | -350ê±´ (-77%) |
| **ë°ì´í„° ì†ŒìŠ¤** | 6ê°œ | 7ê°œ (+predictions) | +1ê°œ |
| **ëª¨ë¸ ì„±ê³µë¥ ** | 3/4 (75%) | 4/4 (100%) | +25% |
| **í† í° ì‚¬ìš©** | ë†’ìŒ (ë‰´ìŠ¤ í¬í•¨) | ì¤‘ê°„ (ë‰´ìŠ¤ ì œê±°) | -20~30% |

### 3. API ì‘ë‹µ ê²€ì¦

```json
{
  "analysis_summary": {
    "model_a": {
      "model_name": "Qwen3 Max",
      "data_sources_used": [
        "stock_prices",
        "investor_flow",
        "financial_metrics",
        "company_info",
        "technical_indicators",
        "market_trends"
      ],
      "limitations": [
        "ê°œë³„ ì‚¬ì—…ë¶€ë³„ ìˆ˜ìµì„± ë°ì´í„° ë¯¸í¬í•¨",
        "ê¸€ë¡œë²Œ ë°˜ë„ì²´ ì¬ê³  ìˆ˜ì¤€ ë°ì´í„° ë¶€ì¬"
      ],
      "overall_summary": "ì‚¼ì„±ì „ìëŠ” ë‹¨ê¸°ì ìœ¼ë¡œ ì™¸êµ­ì¸ ë§¤ë„ ì••ë ¥ê³¼...",
      "short_term_scenario": "ë‹¨ê¸°ì ìœ¼ë¡œ ì™¸êµ­ì¸ì˜ ìµœê·¼ 3ì¼ ì—°ì†...",
      "medium_term_scenario": "ìµœê·¼ 3ê°œ ë¶„ê¸° ROE ê°œì„  ì¶”ì„¸...",
      "long_term_scenario": "ì¥ê¸°ì ìœ¼ë¡œ ë°˜ë„ì²´ ìˆ˜ìš” íšŒë³µ...",
      "risk_factors": ["ì™¸êµ­ì¸ íˆ¬ììì˜ ë°˜ë„ì²´ ì„¹í„° ì§‘ì¤‘ ë§¤ë„..."],
      "opportunity_factors": ["ë°˜ë„ì²´ ë©”ëª¨ë¦¬ ê°€ê²© ìƒìŠ¹ ì‚¬ì´í´..."],
      "recommendation": "ê´€ë§. ë‹¨ê¸° ë§¤ë„ì„¸ì™€ ì™¸êµ­ì¸ ìˆ˜ê¸‰ ë¶ˆì•ˆì´...",
      "confidence_level": "medium",
      "meta": {
        "last_updated": "2025-11-21T20:01:33",
        "based_on_prediction_count": 109
      }
    }
  }
}
```

âœ… **ëª¨ë“  í•„ë“œ ì •ìƒ ë°˜í™˜**

### 4. í”„ë¡ íŠ¸ì—”ë“œ UI ê²€ì¦

**A/B í…ŒìŠ¤íŠ¸ ëª¨ë“œ (Model A vs Model B)**:

| ì„¹ì…˜ | ì´ì „ | ì´í›„ | ìƒíƒœ |
|------|------|------|------|
| ì‹ ë¢°ë„ | âœ… | âœ… | ìœ ì§€ |
| **ë°ì´í„° ì†ŒìŠ¤** | âŒ | âœ… | ì¶”ê°€ |
| **ì œí•œì‚¬í•­** | âŒ | âœ… | ì¶”ê°€ |
| ì¢…í•© ì˜ê²¬ | âœ… (ë°•ìŠ¤ ì—†ìŒ) | âœ… (ë°•ìŠ¤ ì¶”ê°€) | ê°œì„  |
| **ê¸°ê°„ë³„ ì „ëµ** | âŒ | âœ… | ì¶”ê°€ |
| **ë¦¬ìŠ¤í¬ & ê¸°íšŒ** | âŒ | âœ… | ì¶”ê°€ |
| ìµœì¢… ì¶”ì²œ | âœ… (ë°•ìŠ¤ ì—†ìŒ) | âœ… (ë°•ìŠ¤ ì¶”ê°€) | ê°œì„  |

âœ… **ëª¨ë“  ì„¹ì…˜ í‘œì‹œ í™•ì¸**

### 5. ë³‘ë ¬ ì²˜ë¦¬ ê²€ì¦

```bash
# 4ê°œ ëª¨ë¸ ë™ì‹œ ì‹¤í–‰
â±ï¸ ì‹œì‘: 20:01:01
  â³ GPT-4o ì‹œì‘
  â³ Qwen3 Max ì‹œì‘
  â³ DeepSeek V3.2 ì‹œì‘
  â³ gpt-5-mini ì‹œì‘

  âœ… GPT-4o ì™„ë£Œ (20ì´ˆ)
  âœ… DeepSeek V3.2 ì™„ë£Œ (27ì´ˆ)
  âœ… Qwen3 Max ì™„ë£Œ (33ì´ˆ)
  âœ… gpt-5-mini ì™„ë£Œ (35ì´ˆ)
â±ï¸ ì¢…ë£Œ: 20:01:35

ì´ ì†Œìš” ì‹œê°„: 35ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬)
ìˆœì°¨ ì²˜ë¦¬ ì˜ˆìƒ: 115ì´ˆ (20+27+33+35)
ì„±ëŠ¥ í–¥ìƒ: 3.3ë°° ë¹ ë¦„ ğŸš€
```

---

## ì‚¬ìš© ë°©ë²•

### 1. ì‹ ê·œ ì¢…ëª© ì¶”ê°€

```bash
# API í˜¸ì¶œë¡œ ì¢…ëª© ì¶”ê°€ (ìë™ìœ¼ë¡œ í†µí•© ë¦¬í¬íŠ¸ ìƒì„±)
curl -X POST http://localhost:8000/api/stocks \
  -H "Content-Type: application/json" \
  -d '{
    "code": "035720",
    "name": "ì¹´ì¹´ì˜¤"
  }'

# ë¡œê·¸ í™•ì¸
pm2 logs azak-backend | grep "035720"

# ì¶œë ¥:
# ğŸ“Š Unified report generation for 035720
# âœ… Unified report generation complete: 4/4 models succeeded
```

### 2. Force Update (ìˆ˜ë™ ì—…ë°ì´íŠ¸)

```bash
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ "ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸" ë²„íŠ¼ í´ë¦­
# ë˜ëŠ” API ì§ì ‘ í˜¸ì¶œ

curl -X POST http://localhost:8000/api/dashboard/force-update/005930
```

### 3. ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

```python
# backend/scheduler/crawler_scheduler.py

# ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤ì¼€ì¤„ (í˜„ì¬ ì„¤ì •)
- í‰ì¼ ì¥ ë§ˆê° í›„: 15:30
- í‰ì¼ ì €ë…: 21:00
- í‰ì¼ ì‹¬ì•¼: 02:00
```

### 4. ë¦¬í¬íŠ¸ ì¡°íšŒ

```bash
# APIë¥¼ í†µí•œ ì¡°íšŒ
curl http://localhost:8000/api/stocks/005930

# ì‘ë‹µ í™•ì¸
{
  "analysis_summary": {
    "overall_summary": "...",
    "data_sources_used": ["stock_prices", "investor_flow", ...],
    "meta": {
      "based_on_prediction_count": 109
    }
  }
}
```

---

## ì°¸ê³  ì‚¬í•­

### 1. ì•„í‚¤í…ì²˜ ë¹„êµ

| í•­ëª© | ì´ì „ (ë¶„ë¦¬) | ì´í›„ (í†µí•©) |
|------|-----------|-----------|
| **ì§„ì… í•¨ìˆ˜** | 2ê°œ (`generate_stock_report`, `update_stock_analysis_summary`) | 1ê°œ (`generate_unified_stock_report`) |
| **ë°ì´í„° ìˆ˜ì§‘** | ë¶„ë¦¬ (DB ë˜ëŠ” Prediction) | í†µí•© (DB + Prediction) |
| **í”„ë¡¬í”„íŠ¸ ìƒì„±** | 2ê°œ í•¨ìˆ˜ | 1ê°œ í•¨ìˆ˜ (`build_unified_prompt`) |
| **ì½”ë“œ ë¼ì¸ ìˆ˜** | 436ì¤„ (ì¤‘ë³µ í¬í•¨) | 0ì¤„ (ì¤‘ë³µ ì œê±°) |
| **ìœ ì§€ë³´ìˆ˜ì„±** | ë‚®ìŒ (2ê³³ ìˆ˜ì • í•„ìš”) | ë†’ìŒ (1ê³³ë§Œ ìˆ˜ì •) |
| **ì¼ê´€ì„±** | ë‚®ìŒ (ì§„ì…ì ë§ˆë‹¤ ë‹¤ë¦„) | ë†’ìŒ (í•­ìƒ ë™ì¼) |

### 2. ë°ì´í„° ìµœì í™” íš¨ê³¼

| í•­ëª© | ë³€ê²½ ì „ | ë³€ê²½ í›„ | íš¨ê³¼ |
|------|---------|---------|------|
| **ì˜ˆì¸¡ ê¸°ê°„** | ìµœê·¼ 30ì¼ | ìµœê·¼ 7ì¼ | ë°ì´í„° ì‹ ì„ ë„ â†‘ |
| **ì˜ˆì¸¡ ê±´ìˆ˜** | ~459ê±´ | ~109ê±´ | ì²˜ë¦¬ ì†ë„ â†‘ |
| **ì˜ˆì¸¡ ìƒ˜í”Œ** | 5ê°œ | 5ê°œ (ìœ ì§€) | - |
| **ë‰´ìŠ¤ ì›ë¬¸** | âœ… í¬í•¨ | âŒ ì œê±° | í† í° 20~30% â†“ |
| **ì €ì‘ê¶Œ ë¦¬ìŠ¤í¬** | âš ï¸ ìˆìŒ | âœ… ì—†ìŒ | ë²•ì  ì•ˆì „ â†‘ |

### 3. ì£¼ì˜ ì‚¬í•­

#### âš ï¸ ë°±ì—”ë“œ ì¬ì‹œì‘

ì½”ë“œ ë³€ê²½ í›„ **ë°˜ë“œì‹œ** ë°±ì—”ë“œ ì¬ì‹œì‘:
```bash
pm2 restart azak-backend
```

#### âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš”

ì´ë²ˆ ë³€ê²½ì‚¬í•­ì€ **DB ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì—†ìŒ**. ê¸°ì¡´ DB ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥.

#### âš ï¸ ê¸°ì¡´ ë¦¬í¬íŠ¸ ìœ ì§€

ì´ì „ì— ìƒì„±ëœ ë¦¬í¬íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ë©°, ìƒˆë¡œìš´ ë¦¬í¬íŠ¸ ìƒì„± ì‹œ í†µí•© í•¨ìˆ˜ ì‚¬ìš©.

### 4. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### ë¬¸ì œ: "ë¶„ì„ ê¸°ì¤€: 0ê±´ì˜ ì˜ˆì¸¡" í‘œì‹œ

```bash
# ì›ì¸: êµ¬ í•¨ìˆ˜ í˜¸ì¶œ ë˜ëŠ” ë°ì´í„° ì—†ìŒ
# í•´ê²°:
1. ë°±ì—”ë“œ ì¬ì‹œì‘
pm2 restart azak-backend

2. Force Update ì‹¤í–‰
curl -X POST http://localhost:8000/api/dashboard/force-update/{stock_code}
```

#### ë¬¸ì œ: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„¹ì…˜ ë¯¸í‘œì‹œ

```bash
# ì›ì¸: ìºì‹œëœ ë°ì´í„° ë˜ëŠ” API ì‘ë‹µ ì˜¤ë¥˜
# í•´ê²°:
1. ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨ (Cmd+Shift+R / Ctrl+Shift+R)
2. API ì‘ë‹µ í™•ì¸
curl http://localhost:8000/api/stocks/{stock_code} | jq '.analysis_summary'
```

#### ë¬¸ì œ: Qwen3 Max JSON íŒŒì‹± ì—ëŸ¬

```bash
# ì¦ìƒ: JSONDecodeError: Expecting value: line 1 column 1 (char 0)
# ì›ì¸: ì¼ì‹œì  API ì˜¤ë¥˜ (OpenRouter ë¶ˆì•ˆì •)
# í•´ê²°: ìë™ ì¬ì‹œë„ (ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ ë¨)

# ë¡œê·¸ì—ì„œ í™•ì¸ ê°€ëŠ¥:
# âŒ Qwen3 Max JSON parse error. Response: {first 500 chars}
```

---

## ê´€ë ¨ íŒŒì¼

### ìˆ˜ì •ëœ íŒŒì¼

#### ë°±ì—”ë“œ
- `backend/services/stock_analysis_service.py`
  - ì‹ ê·œ: `generate_unified_stock_report()` - í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
  - ì‹ ê·œ: `build_unified_context()` - í†µí•© ë°ì´í„° ìˆ˜ì§‘
  - ìˆ˜ì •: `trigger_initial_analysis()` - í†µí•© í•¨ìˆ˜ í˜¸ì¶œ
  - ìˆ˜ì •: `_format_summary_output()` - ë°ì´í„° í˜•ì‹ ë³€í™˜
  - ì œê±°: `generate_stock_report()` - deprecated
  - ì œê±°: `generate_db_based_report()` - deprecated
  - ì œê±°: `update_stock_analysis_summary()` - deprecated

- `backend/llm/investment_report.py`
  - ì‹ ê·œ: `build_unified_prompt()` - í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±
  - ì œê±°: ë‰´ìŠ¤ ì›ë¬¸ ì„¹ì…˜ ì½”ë“œ

- `backend/scheduler/crawler_scheduler.py`
  - ìˆ˜ì •: `_generate_stock_reports()` - í†µí•© í•¨ìˆ˜ í˜¸ì¶œ

- `backend/api/dashboard.py`
  - ìˆ˜ì •: `_generate_report_background()` - í†µí•© í•¨ìˆ˜ í˜¸ì¶œ
  - ìˆ˜ì •: `force_update_stale_reports()` - í†µí•© í•¨ìˆ˜ í˜¸ì¶œ

- `backend/api/stocks.py`
  - ì œê±°: `update_stock_analysis_summary` import

#### í”„ë¡ íŠ¸ì—”ë“œ
- `frontend/app/components/StockDetailView.tsx`
  - ìˆ˜ì •: `renderModelSummary()` - ì „ì²´ ì„¹ì…˜ í‘œì‹œ
  - ì¶”ê°€: ì¢…í•© ì˜ê²¬ ë°•ìŠ¤ ìŠ¤íƒ€ì¼
  - ì¶”ê°€: ìµœì¢… ì¶”ì²œ ë°•ìŠ¤ ìŠ¤íƒ€ì¼

### ì œê±°ëœ ì½”ë“œ

| íŒŒì¼ | ì œê±° ë‚´ìš© | ë¼ì¸ ìˆ˜ |
|------|----------|---------|
| `stock_analysis_service.py` | `generate_stock_report()` | ~187ì¤„ |
| `stock_analysis_service.py` | `generate_db_based_report()` | ~8ì¤„ |
| `stock_analysis_service.py` | `update_stock_analysis_summary()` | ~241ì¤„ |
| `stocks.py` | deprecated import | 1ì¤„ |
| **í•©ê³„** | | **437ì¤„** |

---

## ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë²„ì „ | ë³€ê²½ ë‚´ìš© |
|------|------|----------|
| 2025-11-21 | 2.0.0 | í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì•„í‚¤í…ì²˜ êµ¬ì¶• (ë‹¨ì¼ í•¨ìˆ˜, ë°ì´í„° í†µí•©, 436ì¤„ ì œê±°) |

---

**ì‘ì„±ì¼**: 2025-11-21
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-11-21
**ì‘ì„±ì**: Development Team
