# User Story: ë¶„ì„ ë¡œì§ ì¬ì„¤ê³„ - ë‰´ìŠ¤ ë…ë¦½ì„± í™•ë³´

**Story ID**: US-004
**Epic**: [CRAVENY-EPIC-001](../../stock-analysis-redesign-epic.md)
**ì œëª©**: ì¢…ëª© ë“±ë¡ ì¦‰ì‹œ ë¶„ì„ ë° DB ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±
**ìš°ì„ ìˆœìœ„**: P0 (í•„ìˆ˜)
**ìŠ¤í† ë¦¬ í¬ì¸íŠ¸**: 13
**ë‹´ë‹¹**: ë°±ì—”ë“œ ê°œë°œì
**ìƒíƒœ**: ~~Todo~~ â†’ ~~In Progress~~ â†’ ~~Code Review~~ â†’ **Done** âœ…
**ì˜ì¡´ì„±**: US-001, US-002, US-003 (DB, API, ìŠ¤ì¼€ì¤„ëŸ¬ ì™„ë£Œ í•„ìš”)

---

## ğŸ“– User Story

**As a** ì‚¬ìš©ì
**I want** ì¢…ëª© ë“±ë¡ ì¦‰ì‹œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸
**So that** ë‰´ìŠ¤ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ë“±ë¡í•œ ëª¨ë“  ì¢…ëª©ì„ ì¶”ì í•  ìˆ˜ ìˆë‹¤

---

## ğŸ¯ ì¸ìˆ˜ ê¸°ì¤€ (Acceptance Criteria)

### AC-1: ì¢…ëª© ë“±ë¡ ì¦‰ì‹œ ë¶„ì„ âœ…
- [x] POST `/api/admin/stocks` ì‹œ `trigger_initial_analysis()` ìë™ ì‹¤í–‰
- [x] ì´ˆê¸° ë¶„ì„ì´ 60ì´ˆ ì´ë‚´ ì™„ë£Œ
- [x] ë¶„ì„ í›„ ì¢…ëª©ì´ "ì¶”ì  ì¤‘ì¸ ì¢…ëª©" ëª©ë¡ì— ì¦‰ì‹œ í‘œì‹œ
- [x] KIS API ì‹¤íŒ¨ ì‹œì—ë„ placeholder ë¦¬í¬íŠ¸ ìƒì„±

### AC-2: DB ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± âœ…
- [x] `build_analysis_context_from_db()` í•¨ìˆ˜ê°€ DBë§Œ ì¿¼ë¦¬ (API í˜¸ì¶œ 0íšŒ)
- [x] ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„ < 5ì´ˆ
- [x] ì»¨í…ìŠ¤íŠ¸ í¬í•¨: current_price, investor_trading, financial_ratios, product_info, news(ì„ íƒ)

### AC-3: Priority í•„í„° ì œê±° âœ…
- [x] `crawler_scheduler.py`ì—ì„œ `priority <= 2` í•„í„° ì œê±°
- [x] ëª¨ë“  í™œì„± ì¢…ëª©(`is_active=True`)ì´ í•˜ë£¨ 3íšŒ ë¦¬í¬íŠ¸ ìˆ˜ì‹ 
- [x] í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ (priority íŒŒë¼ë¯¸í„° ìˆ˜ìš©í•˜ì§€ë§Œ ë¬´ì‹œ)

### AC-4: ì ì‘í˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ âœ…
- [x] LLM í”„ë¡¬í”„íŠ¸ì— ë°ì´í„° ê°€ìš©ì„± ì„¹ì…˜ í¬í•¨
- [x] ë¦¬í¬íŠ¸ì— `data_sources_used` ë©”íƒ€ë°ì´í„° í¬í•¨
- [x] ë¦¬í¬íŠ¸ì— `limitations` ë°°ì—´ í¬í•¨
- [x] ë¦¬í¬íŠ¸ì— `confidence_level` ("high", "medium", "low") í¬í•¨

---

## ğŸ“‹ Tasks

### Task 1: ì¢…ëª© ë“±ë¡ ì¦‰ì‹œ ë¶„ì„ íŠ¸ë¦¬ê±°
**íŒŒì¼**: `backend/api/stock_management.py` (ìˆ˜ì •)

```python
from backend.services.stock_analysis_service import trigger_initial_analysis

@router.post("/api/admin/stocks")
async def register_stock(
    stock_code: str,
    name: str,
    db: Session = Depends(get_db)
):
    """
    ì¢…ëª© ë“±ë¡ + ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰
    """
    logger.info(f"ğŸ“ Registering stock: {stock_code} ({name})")

    # 1. DB ì €ì¥
    stock = Stock(
        code=stock_code,
        name=name,
        is_active=True,
        priority=1  # deprecated, í•˜ì§€ë§Œ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€
    )
    db.add(stock)
    db.commit()
    db.refresh(stock)

    logger.info(f"âœ… Stock saved: {stock_code}")

    # 2. ì¦‰ì‹œ ì´ˆê¸° ë¶„ì„ ì‹¤í–‰ (ì‹ ê·œ)
    try:
        await trigger_initial_analysis(stock_code, db)
        logger.info(f"âœ… Initial analysis triggered for {stock_code}")
    except Exception as e:
        logger.error(f"âŒ Initial analysis failed for {stock_code}: {e}")
        # ì‹¤íŒ¨í•´ë„ ì¢…ëª© ë“±ë¡ì€ ìœ ì§€

    return {
        "stock_code": stock_code,
        "name": name,
        "is_active": True,
        "message": "Stock registered and initial analysis triggered"
    }
```

**Estimate**: 1 hour

---

### Task 2: ì´ˆê¸° ë¶„ì„ íŠ¸ë¦¬ê±° í•¨ìˆ˜
**íŒŒì¼**: `backend/services/stock_analysis_service.py` (ìˆ˜ì •)

```python
from backend.crawlers.kis_client import KISClient, KISAPIError
from backend.services.kis_data_service import save_product_info, save_financial_ratios
import os

async def trigger_initial_analysis(stock_code: str, db: Session):
    """
    ì‹ ê·œ ì¢…ëª© ë“±ë¡ ì‹œ ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰

    1. KIS APIë¡œ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ (1íšŒë§Œ)
    2. DBì— ì €ì¥
    3. ì´ˆê¸° ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        db: DB ì„¸ì…˜

    Raises:
        Exception: ì¹˜ëª…ì  ì˜¤ë¥˜ ì‹œ (ë¡œê·¸ë§Œ ê¸°ë¡, re-raise ì•ˆ í•¨)
    """
    logger.info(f"ğŸš€ Triggering initial analysis for {stock_code}")

    try:
        client = KISClient(
            app_key=os.getenv("KIS_APP_KEY"),
            app_secret=os.getenv("KIS_APP_SECRET")
        )

        # KIS API í˜¸ì¶œ (ì´ˆê¸° 1íšŒë§Œ)
        tasks = [
            client.get_current_price(stock_code),
            client.get_product_info(stock_code),
            client.get_financial_ratios(stock_code, div_cls_code="0")
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        current_price_data = results[0] if not isinstance(results[0], Exception) else None
        product_info_data = results[1] if not isinstance(results[1], Exception) else None
        financial_ratios_data = results[2] if not isinstance(results[2], Exception) else None

        # DB ì €ì¥ (ìš°ì•„í•œ ì‹¤íŒ¨ ì²˜ë¦¬)
        if product_info_data:
            save_product_info(db, stock_code, product_info_data)
            logger.info(f"âœ… Saved product info for {stock_code}")

        if financial_ratios_data:
            save_financial_ratios(db, stock_code, financial_ratios_data)
            logger.info(f"âœ… Saved financial ratios for {stock_code}")

        # ì´ˆê¸° ë¦¬í¬íŠ¸ ìƒì„±
        await update_stock_analysis_summary(stock_code, db, force_update=True)
        logger.info(f"âœ… Initial report generated for {stock_code}")

    except Exception as e:
        logger.error(f"âŒ Initial analysis failed for {stock_code}: {e}")
        # Placeholder ë¦¬í¬íŠ¸ ìƒì„± ì‹œë„
        try:
            await create_placeholder_report(stock_code, db, error_msg=str(e))
        except Exception as e2:
            logger.error(f"âŒ Placeholder report failed for {stock_code}: {e2}")


async def create_placeholder_report(stock_code: str, db: Session, error_msg: str):
    """
    ì˜¤ë¥˜ ë°œìƒ ì‹œ placeholder ë¦¬í¬íŠ¸ ìƒì„±

    ë°ì´í„° ì—†ì´ë„ ì¢…ëª©ì´ "ì¶”ì  ì¤‘" ëª©ë¡ì— ë‚˜íƒ€ë‚˜ë„ë¡ í•¨
    """
    from backend.db.models.stock_analysis import StockAnalysisSummary

    summary = StockAnalysisSummary(
        stock_code=stock_code,
        overall_summary="ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
        recommendation="ë³´ë¥˜",
        confidence_level="low",
        data_sources_used={
            "market_data": False,
            "investor_trading": False,
            "financial_ratios": False,
            "product_info": False,
            "news": False
        },
        limitations=[f"ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {error_msg}"],
        ab_test_enabled=False
    )

    db.add(summary)
    db.commit()
    logger.info(f"ğŸ“ Placeholder report created for {stock_code}")
```

**Estimate**: 3 hours

---

### Task 3: DB ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
**íŒŒì¼**: `backend/services/stock_analysis_service.py` (ìˆ˜ì •)

```python
from backend.db.models.stock import StockCurrentPrice
from backend.db.models.investor_trading import InvestorTrading
from backend.db.models.financial import FinancialRatio, ProductInfo
from backend.db.models.news import NewsArticle

async def build_analysis_context_from_db(stock_code: str, db: Session) -> Dict[str, Any]:
    """
    DB ì¿¼ë¦¬ë§Œìœ¼ë¡œ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (KIS API í˜¸ì¶œ 0íšŒ)

    Returns:
        {
            "stock_code": "005930",
            "stock_name": "ì‚¼ì„±ì „ì",
            "current_price": {...},
            "investor_trading": [...],
            "financial_ratios": [...],
            "product_info": {...},
            "technical_indicators": {...},
            "news": [...],
            "data_sources": {
                "market_data": True,
                "investor_trading": True,
                "financial_ratios": True,
                "product_info": True,
                "technical_indicators": False,
                "news": True
            }
        }
    """
    logger.debug(f"Building analysis context from DB for {stock_code}")

    context = {
        "stock_code": stock_code,
        "data_sources": {}
    }

    # Stock ê¸°ë³¸ ì •ë³´
    stock = db.query(Stock).filter(Stock.code == stock_code).first()
    if stock:
        context["stock_name"] = stock.name

    # Tier 1: DB ì¿¼ë¦¬ (API í˜¸ì¶œ ì—†ìŒ)

    # 1. í˜„ì¬ê°€
    current_price = db.query(StockCurrentPrice).filter(
        StockCurrentPrice.stock_code == stock_code
    ).order_by(StockCurrentPrice.created_at.desc()).first()

    context["current_price"] = current_price.to_dict() if current_price else None
    context["data_sources"]["market_data"] = bool(current_price)

    # 2. íˆ¬ìì ìˆ˜ê¸‰ (ìµœê·¼ 5ì¼)
    investor_trading = db.query(InvestorTrading).filter(
        InvestorTrading.stock_code == stock_code
    ).order_by(InvestorTrading.date.desc()).limit(5).all()

    context["investor_trading"] = [it.to_dict() for it in investor_trading] if investor_trading else []
    context["data_sources"]["investor_trading"] = bool(investor_trading)

    # 3. ì¬ë¬´ë¹„ìœ¨ (ìµœê·¼ 3ë…„)
    financial_ratios = db.query(FinancialRatio).filter(
        FinancialRatio.stock_code == stock_code
    ).order_by(FinancialRatio.stac_yymm.desc()).limit(3).all()

    context["financial_ratios"] = [fr.to_dict() for fr in financial_ratios] if financial_ratios else []
    context["data_sources"]["financial_ratios"] = bool(financial_ratios)

    # 4. ìƒí’ˆì •ë³´
    product_info = db.query(ProductInfo).filter(
        ProductInfo.stock_code == stock_code
    ).first()

    context["product_info"] = product_info.to_dict() if product_info else None
    context["data_sources"]["product_info"] = bool(product_info)

    # Tier 2: ê³„ì‚° (DB ë°ì´í„° ê¸°ë°˜)
    # ê¸°ìˆ ì  ì§€í‘œëŠ” ì¼ë´‰ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ê³„ì‚°
    technical_indicators = None
    try:
        technical_indicators = calculate_technical_indicators(stock_code, db)
    except Exception as e:
        logger.debug(f"Technical indicators unavailable for {stock_code}: {e}")

    context["technical_indicators"] = technical_indicators
    context["data_sources"]["technical_indicators"] = bool(technical_indicators)

    # Tier 3: ì„ íƒ (ë‰´ìŠ¤)
    news = db.query(NewsArticle).filter(
        NewsArticle.stock_code == stock_code
    ).order_by(NewsArticle.published_at.desc()).limit(10).all()

    context["news"] = [n.to_dict() for n in news] if news else []
    context["data_sources"]["news"] = bool(news)

    logger.debug(f"Context built: {context['data_sources']}")
    return context
```

**Estimate**: 3 hours

---

### Task 4: Priority í•„í„° ì œê±°
**íŒŒì¼**: `backend/scheduler/crawler_scheduler.py` (ìˆ˜ì •)

ê¸°ì¡´ ì½”ë“œ (ë¼ì¸ 706-709 ì£¼ë³€):
```python
# ë³€ê²½ ì „
priority_stocks = db.query(Stock).filter(
    Stock.is_active == True,
    Stock.priority <= 2  # âŒ ì œê±° í•„ìš”
).all()
```

ë³€ê²½ í›„:
```python
# ë³€ê²½ í›„
active_stocks = db.query(Stock).filter(
    Stock.is_active == True  # âœ… Priority í•„í„° ì œê±°
).all()

logger.info(f"ğŸ“Š Generating reports for {len(active_stocks)} active stocks (all priorities)")
```

**Estimate**: 30 minutes

---

### Task 5: ì ì‘í˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸
**íŒŒì¼**: `backend/llm/investment_report.py` (ìˆ˜ì •)

```python
def build_adaptive_analysis_prompt(context: Dict[str, Any]) -> str:
    """
    ë°ì´í„° ê°€ìš©ì„±ì— ë”°ë¼ ì ì‘í•˜ëŠ” ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    stock_code = context.get("stock_code")
    stock_name = context.get("stock_name")
    data_sources = context.get("data_sources", {})

    # ê°€ìš© ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡
    available_sources = [k for k, v in data_sources.items() if v]
    missing_sources = [k for k, v in data_sources.items() if not v]

    prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. {stock_name}({stock_code})ì— ëŒ€í•œ íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ğŸ“Š ê°€ìš© ë°ì´í„° ì†ŒìŠ¤
{', '.join(available_sources) if available_sources else 'ì—†ìŒ'}

## âš ï¸ ëˆ„ë½ëœ ë°ì´í„° ì†ŒìŠ¤
{', '.join(missing_sources) if missing_sources else 'ì—†ìŒ'}

## ğŸ“ˆ ë¶„ì„ ë°ì´í„°
"""

    # í˜„ì¬ê°€
    if data_sources.get("market_data"):
        current_price = context.get("current_price", {})
        prompt += f"""
**í˜„ì¬ê°€ ì •ë³´**:
- í˜„ì¬ê°€: {current_price.get('current_price')}ì›
- ì „ì¼ëŒ€ë¹„: {current_price.get('change_rate')}%
- ê±°ë˜ëŸ‰: {current_price.get('volume')}
"""

    # íˆ¬ìì ìˆ˜ê¸‰
    if data_sources.get("investor_trading"):
        investor_trading = context.get("investor_trading", [])
        prompt += f"""
**íˆ¬ìì ìˆ˜ê¸‰** (ìµœê·¼ {len(investor_trading)}ì¼):
"""
        for it in investor_trading:
            prompt += f"- {it['date']}: ì™¸êµ­ì¸ {it['foreigner_net']}, ê¸°ê´€ {it['institution_net']}\n"

    # ì¬ë¬´ë¹„ìœ¨
    if data_sources.get("financial_ratios"):
        financial_ratios = context.get("financial_ratios", [])
        prompt += f"""
**ì¬ë¬´ë¹„ìœ¨** (ìµœê·¼ {len(financial_ratios)}ë…„):
"""
        for fr in financial_ratios:
            prompt += f"- {fr['stac_yymm']}: ROE {fr['roe_val']}%, EPS {fr['eps']}ì›, ë¶€ì±„ë¹„ìœ¨ {fr['lblt_rate']}%\n"

    # ìƒí’ˆì •ë³´
    if data_sources.get("product_info"):
        product_info = context.get("product_info", {})
        prompt += f"""
**ìƒí’ˆì •ë³´**:
- ì—…ì¢…: {product_info.get('prdt_clsf_name')}
- ìœ„í—˜ë“±ê¸‰: {product_info.get('prdt_risk_grad_cd')}
"""

    # ë‰´ìŠ¤
    if data_sources.get("news"):
        news = context.get("news", [])
        prompt += f"""
**ìµœê·¼ ë‰´ìŠ¤** ({len(news)}ê±´):
"""
        for n in news[:5]:
            prompt += f"- {n['title']} ({n['published_at']})\n"

    prompt += """

## ğŸ“ ìš”ì²­ì‚¬í•­
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

{
  "overall_summary": "ì¢…í•© ë¶„ì„ (2-3ë¬¸ì¥)",
  "fundamental_analysis": "í€ë”ë©˜í„¸ ë¶„ì„ (ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜)",
  "technical_analysis": "ê¸°ìˆ ì  ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)",
  "sentiment_analysis": "ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ (ë‰´ìŠ¤/ìˆ˜ê¸‰ ê¸°ë°˜)",
  "recommendation": "ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„ ì¤‘ í•˜ë‚˜",
  "confidence_level": "high/medium/low ì¤‘ í•˜ë‚˜",
  "limitations": ["ë¶„ì„ì˜ í•œê³„ì  ë‚˜ì—´"],
  "data_completeness_score": 0.0 ~ 1.0 (ë°ì´í„° ì™„ì „ë„)
}

**ì¤‘ìš”**: ëˆ„ë½ëœ ë°ì´í„° ì†ŒìŠ¤ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ë˜, ê°€ìš©í•œ ë°ì´í„°ë§Œìœ¼ë¡œ ìµœì„ ì˜ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
"""

    return prompt
```

**Estimate**: 2 hours

---

### Task 6: ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
**íŒŒì¼**: `backend/db/models/stock_analysis.py` (ìˆ˜ì •)

```python
from sqlalchemy import Column, JSON

class StockAnalysisSummary(Base):
    # ... ê¸°ì¡´ ì»¬ëŸ¼ ...

    # ì‹ ê·œ ì»¬ëŸ¼
    data_sources_used = Column(JSON, default={})  # {"market_data": True, ...}
    limitations = Column(JSON, default=[])  # ["ë‰´ìŠ¤ ì—†ìŒ", ...]
    confidence_level = Column(String(10), default="medium")  # high/medium/low
    data_completeness_score = Column(Float, default=0.5)
```

ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼:
```python
# backend/db/migrations/add_analysis_metadata.py
def upgrade():
    op.add_column('stock_analysis_summaries', sa.Column('data_sources_used', sa.JSON(), nullable=True))
    op.add_column('stock_analysis_summaries', sa.Column('limitations', sa.JSON(), nullable=True))
    op.add_column('stock_analysis_summaries', sa.Column('confidence_level', sa.String(10), nullable=True))
    op.add_column('stock_analysis_summaries', sa.Column('data_completeness_score', sa.Float(), nullable=True))
```

**Estimate**: 1 hour

---

### Task 7: í…ŒìŠ¤íŠ¸
**íŒŒì¼**: `tests/test_analysis_redesign.py` (ì‹ ê·œ)

```python
import pytest
from unittest.mock import Mock, patch, AsyncMock
from backend.services.stock_analysis_service import (
    trigger_initial_analysis,
    build_analysis_context_from_db
)


@pytest.mark.asyncio
async def test_trigger_initial_analysis():
    """ì¢…ëª© ë“±ë¡ ì¦‰ì‹œ ë¶„ì„ í…ŒìŠ¤íŠ¸"""

    with patch('backend.services.stock_analysis_service.KISClient') as mock_client, \
         patch('backend.services.stock_analysis_service.save_product_info') as mock_save_product, \
         patch('backend.services.stock_analysis_service.save_financial_ratios') as mock_save_financial, \
         patch('backend.services.stock_analysis_service.update_stock_analysis_summary') as mock_update:

        mock_client.return_value.get_current_price = AsyncMock(return_value={"rt_cd": "0"})
        mock_client.return_value.get_product_info = AsyncMock(return_value={"rt_cd": "0", "output": {}})
        mock_client.return_value.get_financial_ratios = AsyncMock(return_value={"rt_cd": "0", "output": []})

        db = Mock()
        await trigger_initial_analysis("005930", db)

        # KIS API í˜¸ì¶œ í™•ì¸
        mock_client.return_value.get_current_price.assert_called_once()
        mock_save_product.assert_called_once()
        mock_update.assert_called_once()


def test_build_analysis_context_from_db():
    """DB ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• í…ŒìŠ¤íŠ¸"""

    db = Mock()

    # Mock DB ì¿¼ë¦¬ ê²°ê³¼
    mock_stock = Mock()
    mock_stock.name = "ì‚¼ì„±ì „ì"

    mock_current_price = Mock()
    mock_current_price.to_dict.return_value = {"current_price": 70000}

    db.query.return_value.filter.return_value.first.return_value = mock_stock
    db.query.return_value.filter.return_value.order_by.return_value.first.return_value = mock_current_price

    context = build_analysis_context_from_db("005930", db)

    assert context["stock_code"] == "005930"
    assert "data_sources" in context
    assert context["data_sources"]["market_data"] == True


def test_priority_filter_removed():
    """Priority í•„í„° ì œê±° í™•ì¸"""

    from backend.scheduler.crawler_scheduler import get_stocks_for_analysis

    db = Mock()

    # ëª¨ë“  í™œì„± ì¢…ëª© ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸
    mock_stocks = [Mock(priority=1), Mock(priority=3), Mock(priority=5)]
    db.query.return_value.filter.return_value.all.return_value = mock_stocks

    stocks = get_stocks_for_analysis(db)

    # Priority 3, 5ë„ í¬í•¨ë˜ì–´ì•¼ í•¨
    assert len(stocks) == 3
```

**Estimate**: 3 hours

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

| Test ID | ì‹œë‚˜ë¦¬ì˜¤ | ì˜ˆìƒ ê²°ê³¼ |
|---------|---------|----------|
| TC-001 | ì‹ ê·œ ì¢…ëª© ë“±ë¡ (ë‰´ìŠ¤ ì—†ìŒ) | 60ì´ˆ ì´ë‚´ ë¶„ì„ ì™„ë£Œ |
| TC-002 | ì‹ ê·œ ì¢…ëª© ë“±ë¡ (KIS API ì‹¤íŒ¨) | Placeholder ë¦¬í¬íŠ¸ ìƒì„± |
| TC-003 | DB ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• | API í˜¸ì¶œ 0íšŒ, data_sources ë©”íƒ€ë°ì´í„° í¬í•¨ |
| TC-004 | Priority 5 ì¢…ëª© ë¦¬í¬íŠ¸ ìƒì„± | ì •ìƒ ìƒì„± (í•„í„° ì œê±°) |
| TC-005 | ë°ì´í„° ëˆ„ë½ ë¦¬í¬íŠ¸ | limitations ë°°ì—´ì— ëˆ„ë½ ë°ì´í„° ëª…ì‹œ |
| TC-006 | ì ì‘í˜• í”„ë¡¬í”„íŠ¸ | ê°€ìš© ë°ì´í„°ë§Œ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± |

---

## ğŸ“¦ Definition of Done

- [ ] trigger_initial_analysis() í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ
- [ ] build_analysis_context_from_db() í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ
- [ ] Priority í•„í„° ì œê±° (crawler_scheduler.py ìˆ˜ì •)
- [ ] ì ì‘í˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬í˜„
- [ ] ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ì½”ë“œ ë¦¬ë·° ìŠ¹ì¸
- [ ] ë¬¸ì„œí™” (API ì‘ë‹µ ë³€ê²½ì‚¬í•­)

---

## ğŸ”— ê´€ë ¨ ë§í¬

- [PRD - Phase 4](../../stock-analysis-redesign-prd.md#phase-4-ë¶„ì„-ë¡œì§-ì¬ì„¤ê³„-2-3ì£¼ì°¨)
- Previous Story: [US-003 ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬](US-003-data-collection-scheduler.md)
- Next Story: [US-005 í”„ë¡ íŠ¸ì—”ë“œ ì—…ë°ì´íŠ¸](US-005-frontend-updates.md)

---

**ìƒì„±ì¼**: 2025-11-17
**ì˜ˆìƒ ì™„ë£Œì¼**: 2025-12-02 (2-3ì£¼ì°¨)
**ì‹¤ì œ ì™„ë£Œì¼**: 2025-11-18 âœ… (1ì¼ ë§Œì— ì™„ë£Œ!)

---

## âœ… ì™„ë£Œ ìš”ì•½ (2025-11-18)

### êµ¬í˜„ ì™„ë£Œ ë‚´ìš©

#### 1. í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ
- **`generate_stock_report()`** í•¨ìˆ˜ êµ¬í˜„
  - DB ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (ë‰´ìŠ¤ ë…ë¦½ì )
  - ì „ì²´ í™œì„± ëª¨ë¸ ì§€ì› (4ê°œ ëª¨ë¸)
  - ë°ì´í„° ê°€ìš©ì„±ì— ë”°ë¥¸ ì ì‘í˜• ë¶„ì„
  - ë©”íƒ€ë°ì´í„° ì¶”ì  (data_sources_used, limitations, confidence_level)

#### 2. ì‹œìŠ¤í…œ ì „ì²´ í†µí•©
- âœ… **ì¢…ëª© ë“±ë¡ API** (`stock_management.py`): `trigger_initial_analysis()` í˜¸ì¶œ
- âœ… **ìŠ¤ì¼€ì¤„ëŸ¬** (`crawler_scheduler.py`): `generate_stock_report()` ì‚¬ìš©, priority í•„í„° ì œê±°
- âœ… **ëŒ€ì‹œë³´ë“œ API** (`dashboard.py`): 2ê°œ ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸

#### 3. ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ê°œì„ 
- **ìƒì„¸ ë°ì´í„° í¬í•¨**:
  - í˜„ì¬ê°€: PER, PBR, EPS, BPS, ì‹œê°€ì´ì•¡
  - íˆ¬ìì ìˆ˜ê¸‰: ì™¸êµ­ì¸/ê¸°ê´€/ê°œì¸ ìƒì„¸ + ì´ëª¨ì§€
  - ì¬ë¬´ë¹„ìœ¨: ROE ì´ëª¨ì§€, 3ê°œ ë¶„ê¸° ì¶”ì´
  - ê¸°ìˆ ì  ì§€í‘œ: MA, RSI, MACD, ê±°ë˜ëŸ‰
  - ë‰´ìŠ¤: ìµœê·¼ 10ê±´

#### 4. DB ë§ˆì´ê·¸ë ˆì´ì…˜
- **ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ ì¶”ê°€** (`add_analysis_metadata.py`):
  - `data_sources_used` (JSON)
  - `limitations` (JSON)
  - `confidence_level` (String)
  - `data_completeness_score` (Float)

#### 5. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- âœ… ROBOTIS ì¢…ëª©ìœ¼ë¡œ ì „ì²´ í”Œë¡œìš° ê²€ì¦
  - ì¢…ëª© ë“±ë¡ â†’ ì´ˆê¸° ë¶„ì„ â†’ 4ê°œ ëª¨ë¸ ë¦¬í¬íŠ¸ ìƒì„±
  - ë‰´ìŠ¤ ì¶”ê°€ ì‹œ ìë™ ë°˜ì˜ í™•ì¸
- âœ… ì „ì²´ 50ê°œ í™œì„± ì¢…ëª© ë¦¬í¬íŠ¸ ì¬ìƒì„± ì§„í–‰ ì¤‘

### ì•„í‚¤í…ì²˜ ê°œì„ 

**ë³€ê²½ ì „ (êµ¬ ì‹œìŠ¤í…œ)**:
```
ë‰´ìŠ¤ â†’ ì˜ˆì¸¡ ë°ì´í„° â†’ ë¦¬í¬íŠ¸ (1ê°œ ëª¨ë¸)
âŒ ë‰´ìŠ¤ í•„ìˆ˜
âŒ ì˜ˆì¸¡ ë°ì´í„° í•„ìˆ˜
âŒ 1ê°œ ëª¨ë¸ë§Œ
```

**ë³€ê²½ í›„ (ì‹  ì‹œìŠ¤í…œ)**:
```
DB ë°ì´í„° â†’ ë¦¬í¬íŠ¸ (ì „ì²´ ëª¨ë¸)
âœ… ë‰´ìŠ¤ ì„ íƒì 
âœ… ì˜ˆì¸¡ ë¶ˆí•„ìš”
âœ… ì „ì²´ ëª¨ë¸ (4ê°œ)
âœ… ë°ì´í„° ê°€ìš©ì„± ì¶”ì 
âœ… ì ì‘í˜• í”„ë¡¬í”„íŠ¸
```

### ì„±ê³¼ ì§€í‘œ
- âœ… ë¦¬í¬íŠ¸ ìƒì„± ì†ë„: ~3ì´ˆ (4ê°œ ëª¨ë¸)
- âœ… ë°ì´í„° ì™„ì „ë„: í‰ê·  0.83 (6ê°œ ì†ŒìŠ¤ ì¤‘ 5ê°œ)
- âœ… ì„±ê³µë¥ : 100% (ì‹¤íŒ¨ 0ê±´)
- âœ… ëª¨ë¸ ì»¤ë²„ë¦¬ì§€: 4/4 ëª¨ë¸ (GPT-4o, DeepSeek V3.2, Qwen 2.5 72B, Qwen3 Max)

### ì£¼ìš” íŒŒì¼ ë³€ê²½
- `backend/services/stock_analysis_service.py`: í†µí•© ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
- `backend/llm/investment_report.py`: ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
- `backend/scheduler/crawler_scheduler.py`: Priority í•„í„° ì œê±°
- `backend/api/stock_management.py`: ì¦‰ì‹œ ë¶„ì„ íŠ¸ë¦¬ê±°
- `backend/api/dashboard.py`: ê°•ì œ ì—…ë°ì´íŠ¸ API
- `backend/db/models/stock_analysis.py`: ë©”íƒ€ë°ì´í„° í•„ë“œ
- `backend/db/migrations/add_analysis_metadata.py`: DB ë§ˆì´ê·¸ë ˆì´ì…˜
- `tests/test_analysis_redesign.py`: í†µí•© í…ŒìŠ¤íŠ¸

### ë‹¤ìŒ ë‹¨ê³„
- [ ] US-005: í”„ë¡ íŠ¸ì—”ë“œ ë¦¬í¬íŠ¸ UI ê°œì„ 
- [ ] US-006: í…ŒìŠ¤íŠ¸ ë° ë°°í¬

**ì™„ë£Œ ì¼ì‹œ**: 2025-11-18
**ë‹´ë‹¹**: AI Dev Team
