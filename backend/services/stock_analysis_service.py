"""
Stock Analysis Service

ì˜ˆì¸¡ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì¢…í•© íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì„œë¹„ìŠ¤
"""
import logging
import json
import re
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
from sqlalchemy.orm import Session
from sqlalchemy import func

from backend.db.models.prediction import Prediction
from backend.db.models.stock_analysis import StockAnalysisSummary
from backend.db.models.stock import StockPrice, Stock
from backend.db.models.model import Model
from backend.db.models.ab_test_config import ABTestConfig
from backend.db.models.market_data import StockCurrentPrice, InvestorTrading
from backend.db.models.financial import FinancialRatio, ProductInfo
from backend.db.models.news import NewsArticle
from backend.llm.investment_report import get_report_generator
from backend.utils.stock_mapping import get_stock_mapper
from backend.utils.market_time import (
    get_market_phase,
    get_ttl_hours,
    get_price_threshold,
    get_direction_threshold
)
from backend.crawlers.kis_client import KISClient
from backend.services.kis_data_service import save_product_info, save_financial_ratios


logger = logging.getLogger(__name__)


async def trigger_initial_analysis(stock_code: str, db: Session):
    """
    ì‹ ê·œ ì¢…ëª© ë“±ë¡ ì‹œ ì¦‰ì‹œ ë¶„ì„ ì‹¤í–‰

    1. KIS APIë¡œ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ (1íšŒë§Œ)
    2. DBì— ì €ì¥
    3. ì´ˆê¸° ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        db: DB ì„¸ì…˜

    Raises:
        Exception: ì¹˜ëª…ì  ì˜¤ë¥˜ ì‹œ (ë¡œê·¸ë§Œ ê¸°ë¡, re-raise ì•ˆ í•¨)
    """
    logger.info(f"ğŸš€ Triggering initial analysis for {stock_code}")

    try:
        client = KISClient()

        # KIS API í˜¸ì¶œ (ì´ˆê¸° 1íšŒë§Œ)
        tasks = [
            client.get_current_price(stock_code),
            client.get_product_info(stock_code),
            client.get_financial_ratios(stock_code, div_cls_code="0")
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        current_price_data = results[0] if not isinstance(results[0], Exception) else None
        product_info_data = results[1] if not isinstance(results[1], Exception) else None
        financial_ratios_data = results[2] if not isinstance(results[2], Exception) else None

        # DB ì €ì¥ (ìš°ì•„í•œ ì‹¤íŒ¨ ì²˜ë¦¬)
        if product_info_data:
            save_product_info(db, stock_code, product_info_data)
            logger.info(f"âœ… Saved product info for {stock_code}")

        if financial_ratios_data:
            save_financial_ratios(db, stock_code, financial_ratios_data)
            logger.info(f"âœ… Saved financial ratios for {stock_code}")

        # ì´ˆê¸° ë¦¬í¬íŠ¸ ìƒì„± (US-004: DB ê¸°ë°˜, ì „ì²´ ëª¨ë¸)
        reports = await generate_stock_report(stock_code, db)

        if reports:
            logger.info(f"âœ… Initial DB-based reports generated for {stock_code} ({len(reports)} models)")
        else:
            # DB ë°ì´í„°ë„ ì—†ì–´ì„œ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ - Placeholder ìƒì„±
            logger.warning(f"âš ï¸ No data available for {stock_code}, creating placeholder report")
            await create_placeholder_report(
                stock_code, db,
                error_msg="ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘ - KIS API ë°ì´í„° ìˆ˜ì§‘ í›„ ì¬ì‹œë„ ì˜ˆì •"
            )

    except Exception as e:
        logger.error(f"âŒ Initial analysis failed for {stock_code}: {e}")
        # Placeholder ë¦¬í¬íŠ¸ ìƒì„± ì‹œë„
        try:
            await create_placeholder_report(stock_code, db, error_msg=str(e))
        except Exception as e2:
            logger.error(f"âŒ Placeholder report failed for {stock_code}: {e2}")


async def generate_stock_report(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> List[StockAnalysisSummary]:
    """
    ì¢…ëª© ë¦¬í¬íŠ¸ ìƒì„± - DB ê¸°ë°˜, ì „ì²´ ëª¨ë¸ ì§€ì› (US-004 í†µí•© ë²„ì „)

    í”„ë¡œì„¸ìŠ¤:
    1. DBì—ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• (í˜„ì¬ê°€, íˆ¬ìììˆ˜ê¸‰, ì¬ë¬´ë¹„ìœ¨, ìƒí’ˆì •ë³´, ë‰´ìŠ¤)
    2. ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    3. ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
    4. ëª¨ë“  í™œì„± ëª¨ë¸ì— ëŒ€í•´ ë¦¬í¬íŠ¸ ìƒì„±
    5. ë©”íƒ€ë°ì´í„° í¬í•¨ (data_sources_used, limitations, confidence_level)

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        db: DB ì„¸ì…˜
        force_update: ê°•ì œ ì—…ë°ì´íŠ¸ (ê¸°ë³¸ê°’: False)

    Returns:
        ìƒì„±ëœ StockAnalysisSummary ë¦¬ìŠ¤íŠ¸ (ê° ëª¨ë¸ë³„ 1ê°œì”©)
    """
    logger.info(f"ğŸ“Š Generating stock report for {stock_code}")

    try:
        # 1. DBì—ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
        context = await build_analysis_context_from_db(stock_code, db)

        # 2. ë°ì´í„° ê°€ìš©ì„± í™•ì¸
        data_sources = context.get("data_sources", {})
        available_count = sum(1 for v in data_sources.values() if v)

        if available_count == 0:
            logger.warning(f"No data available for {stock_code}")
            return []

        # 3. ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
        from backend.llm.investment_report import build_adaptive_analysis_prompt
        prompt = build_adaptive_analysis_prompt(context)

        # 4. ëª¨ë“  í™œì„± ëª¨ë¸ ì¡°íšŒ
        active_models: List[Model] = db.query(Model).filter(Model.is_active == True).all()

        if not active_models:
            logger.error("No active LLM model found")
            return []

        logger.info(f"ğŸ“‹ Generating reports for {len(active_models)} active models")

        # 5. ê° ëª¨ë¸ë³„ë¡œ ë¦¬í¬íŠ¸ ìƒì„±
        from backend.llm.investment_report import get_report_generator
        generator = get_report_generator()

        created_summaries: List[StockAnalysisSummary] = []
        failed_models = []

        for model in active_models:
            try:
                logger.info(f"  ğŸ”„ Generating report with {model.name} ({model.provider})")

                # LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = generator._create_client(model.provider)

                messages = [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. DB ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
                    },
                    {"role": "user", "content": prompt},
                ]

                kwargs = {
                    "model": model.model_identifier,
                    "messages": messages,
                    "temperature": 0.4,
                    "max_tokens": 1000,
                }

                if model.provider != "openrouter":
                    kwargs["response_format"] = {"type": "json_object"}

                response = client.chat.completions.create(**kwargs)
                result_text = response.choices[0].message.content

                # OpenRouter JSON ì¶”ì¶œ
                if model.provider == "openrouter":
                    result_text = _extract_openrouter_json(result_text)

                # JSON íŒŒì‹±
                report_data = json.loads(result_text)

                # DBì— ì €ì¥
                summary = StockAnalysisSummary(
                    stock_code=stock_code,
                    model_id=model.id,
                    overall_summary=report_data.get("overall_summary"),
                    short_term_scenario=report_data.get("short_term_scenario"),
                    medium_term_scenario=report_data.get("medium_term_scenario"),
                    long_term_scenario=report_data.get("long_term_scenario"),
                    risk_factors=json.dumps(report_data.get("risk_factors", [])) if isinstance(report_data.get("risk_factors"), list) else report_data.get("risk_factors"),
                    opportunity_factors=json.dumps(report_data.get("opportunity_factors", [])) if isinstance(report_data.get("opportunity_factors"), list) else report_data.get("opportunity_factors"),
                    recommendation=report_data.get("recommendation"),
                    confidence_level=report_data.get("confidence_level", "medium"),
                    data_sources_used=data_sources,
                    limitations=report_data.get("limitations", []),
                    data_completeness_score=available_count / 6.0,  # 6ê°œ ë°ì´í„° ì†ŒìŠ¤
                    total_predictions=0,  # DB ê¸°ë°˜ ë¦¬í¬íŠ¸ëŠ” ì˜ˆì¸¡ ì•„ë‹˜
                    based_on_prediction_count=0,
                    # ê°€ê²© ëª©í‘œì¹˜ (ìˆìœ¼ë©´ í¬í•¨)
                    base_price=report_data.get("price_targets", {}).get("base_price"),
                    short_term_target_price=report_data.get("price_targets", {}).get("short_term_target"),
                    short_term_support_price=report_data.get("price_targets", {}).get("short_term_support"),
                    medium_term_target_price=report_data.get("price_targets", {}).get("medium_term_target"),
                    medium_term_support_price=report_data.get("price_targets", {}).get("medium_term_support"),
                    long_term_target_price=report_data.get("price_targets", {}).get("long_term_target"),
                )

                db.add(summary)
                created_summaries.append(summary)
                logger.info(f"  âœ… {model.name} report created (confidence={summary.confidence_level})")

            except Exception as model_error:
                logger.error(
                    f"  âŒ {model.name} report generation failed: {model_error}",
                    exc_info=True
                )
                failed_models.append(model.name)
                continue

        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        if not created_summaries:
            logger.error(f"âŒ All models failed for {stock_code} (failed: {', '.join(failed_models)})")
            return []

        # DB ì»¤ë°‹
        db.commit()
        for summary in created_summaries:
            db.refresh(summary)

        logger.info(f"âœ… Stock report completed: {len(created_summaries)}/{len(active_models)} models succeeded")
        if failed_models:
            logger.warning(f"âš ï¸  Failed models: {', '.join(failed_models)}")

        return created_summaries

    except Exception as e:
        logger.error(f"Failed to generate stock report for {stock_code}: {e}", exc_info=True)
        db.rollback()
        return []


async def generate_db_based_report(stock_code: str, db: Session) -> Optional[StockAnalysisSummary]:
    """
    [DEPRECATED] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    generate_stock_report() ì‚¬ìš© ê¶Œì¥
    """
    reports = await generate_stock_report(stock_code, db)
    return reports[0] if reports else None


async def create_placeholder_report(stock_code: str, db: Session, error_msg: str):
    """
    ì˜¤ë¥˜ ë°œìƒ ì‹œ placeholder ë¦¬í¬íŠ¸ ìƒì„±

    ë°ì´í„° ì—†ì´ë„ ì¢…ëª©ì´ "ì¶”ì  ì¤‘" ëª©ë¡ì— ë‚˜íƒ€ë‚˜ë„ë¡ í•¨
    """
    summary = StockAnalysisSummary(
        stock_code=stock_code,
        overall_summary="ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
        recommendation="ë³´ë¥˜",
        confidence_level="low",
        data_sources_used={
            "market_data": False,
            "investor_trading": False,
            "financial_ratios": False,
            "product_info": False,
            "news": False
        },
        limitations=[f"ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {error_msg}"]
    )

    db.add(summary)
    db.commit()
    logger.info(f"ğŸ“ Placeholder report created for {stock_code}")


async def build_analysis_context_from_db(stock_code: str, db: Session) -> Dict[str, Any]:
    """
    DB ì¿¼ë¦¬ë§Œìœ¼ë¡œ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (KIS API í˜¸ì¶œ 0íšŒ)

    Returns:
        {
            "stock_code": "005930",
            "stock_name": "ì‚¼ì„±ì „ì",
            "current_price": {...},
            "investor_trading": [...],
            "financial_ratios": [...],
            "product_info": {...},
            "technical_indicators": {...},
            "news": [...],
            "data_sources": {
                "market_data": True,
                "investor_trading": True,
                "financial_ratios": True,
                "product_info": True,
                "technical_indicators": False,
                "news": True
            }
        }
    """
    logger.debug(f"Building analysis context from DB for {stock_code}")

    context = {
        "stock_code": stock_code,
        "data_sources": {}
    }

    # Stock ê¸°ë³¸ ì •ë³´
    stock = db.query(Stock).filter(Stock.code == stock_code).first()
    if stock:
        context["stock_name"] = stock.name

    # Tier 1: DB ì¿¼ë¦¬ (API í˜¸ì¶œ ì—†ìŒ)

    # 1. í˜„ì¬ê°€
    current_price = db.query(StockCurrentPrice).filter(
        StockCurrentPrice.stock_code == stock_code
    ).order_by(StockCurrentPrice.created_at.desc()).first()

    if current_price:
        context["current_price"] = {
            "current_price": current_price.stck_prpr,
            "change_rate": current_price.prdy_ctrt,
            "volume": current_price.acml_vol,
            "per": current_price.per,
            "pbr": current_price.pbr,
            "eps": current_price.eps,
            "bps": current_price.bps,
            "market_cap": current_price.hts_avls,
        }
    else:
        context["current_price"] = None
    context["data_sources"]["market_data"] = bool(current_price)

    # 2. íˆ¬ìì ìˆ˜ê¸‰ (ìµœê·¼ 5ì¼)
    investor_trading = db.query(InvestorTrading).filter(
        InvestorTrading.stock_code == stock_code
    ).order_by(InvestorTrading.date.desc()).limit(5).all()

    if investor_trading:
        context["investor_trading"] = [{
            "date": it.date.isoformat() if it.date else None,
            "foreigner_net": it.frgn_ntby_qty,
            "institution_net": it.orgn_ntby_qty,
            "individual_net": it.prsn_ntby_qty,
        } for it in investor_trading]
    else:
        context["investor_trading"] = []
    context["data_sources"]["investor_trading"] = bool(investor_trading)

    # 3. ì¬ë¬´ë¹„ìœ¨ (ìµœê·¼ 3ë…„)
    financial_ratios = db.query(FinancialRatio).filter(
        FinancialRatio.stock_code == stock_code
    ).order_by(FinancialRatio.stac_yymm.desc()).limit(3).all()

    if financial_ratios:
        context["financial_ratios"] = [{
            "stac_yymm": fr.stac_yymm,
            "roe_val": fr.roe_val,
            "eps": fr.eps,
            "bps": fr.bps,
            "lblt_rate": fr.lblt_rate,
        } for fr in financial_ratios]
    else:
        context["financial_ratios"] = []
    context["data_sources"]["financial_ratios"] = bool(financial_ratios)

    # 4. ìƒí’ˆì •ë³´
    product_info = db.query(ProductInfo).filter(
        ProductInfo.stock_code == stock_code
    ).first()

    if product_info:
        context["product_info"] = {
            "prdt_name": product_info.prdt_name,
            "prdt_clsf_name": product_info.prdt_clsf_name,
            "prdt_risk_grad_cd": product_info.prdt_risk_grad_cd,
        }
    else:
        context["product_info"] = None
    context["data_sources"]["product_info"] = bool(product_info)

    # Tier 2: ê³„ì‚° (DB ë°ì´í„° ê¸°ë°˜)
    # ê¸°ìˆ ì  ì§€í‘œëŠ” ì¼ë´‰ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ê³„ì‚°
    technical_indicators = None
    try:
        from backend.utils.technical_indicators import calculate_technical_indicators
        technical_indicators = calculate_technical_indicators(stock_code, db)
    except Exception as e:
        logger.debug(f"Technical indicators unavailable for {stock_code}: {e}")

    context["technical_indicators"] = technical_indicators
    context["data_sources"]["technical_indicators"] = bool(technical_indicators)

    # Tier 3: ì„ íƒ (ë‰´ìŠ¤)
    news = db.query(NewsArticle).filter(
        NewsArticle.stock_code == stock_code
    ).order_by(NewsArticle.published_at.desc()).limit(10).all()

    if news:
        context["news"] = [{
            "title": n.title,
            "content": n.content,
            "published_at": n.published_at.isoformat() if n.published_at else None,
            "source": n.source,
            "url": n.url,
        } for n in news]
    else:
        context["news"] = []
    context["data_sources"]["news"] = bool(news)

    logger.debug(f"Context built: {context['data_sources']}")
    return context


async def should_update_report(
    stock_code: str,
    db: Session,
    existing_summary: Optional[StockAnalysisSummary],
    predictions: list,
    current_price: Optional[Dict[str, Any]],
    force_update: bool
) -> tuple[bool, str]:
    """
    ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ íŒë‹¨ (ì‹œì¥ ì‹œê°„ ê¸°ë°˜)

    Args:
        stock_code: ì¢…ëª© ì½”ë“œ
        db: Database session
        existing_summary: ê¸°ì¡´ ìš”ì•½ (Noneì´ë©´ ì‹ ê·œ ìƒì„±)
        predictions: ìµœê·¼ ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸
        current_price: í˜„ì¬ ì£¼ê°€ ì •ë³´
        force_update: ê°•ì œ ì—…ë°ì´íŠ¸ ì—¬ë¶€

    Returns:
        (ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€, ì‚¬ìœ )
    """
    if force_update or not existing_summary:
        return True, "ê°•ì œ ì—…ë°ì´íŠ¸ ë˜ëŠ” ë¦¬í¬íŠ¸ ì—†ìŒ"

    market_phase = get_market_phase()
    staleness_hours = (datetime.now() - existing_summary.last_updated).total_seconds() / 3600

    # íŠ¸ë¦¬ê±° 1: ì˜ˆì¸¡ ê°œìˆ˜ ì¦ê°€
    total_prediction_count = (
        db.query(func.count(Prediction.id))
        .filter(Prediction.stock_code == stock_code)
        .scalar()
    )

    if existing_summary.based_on_prediction_count < total_prediction_count:
        return True, (
            f"ìƒˆ ì˜ˆì¸¡ ì¶”ê°€ (ê¸°ì¡´: {existing_summary.based_on_prediction_count}, "
            f"í˜„ì¬: {total_prediction_count}, ì‹œì¥: {market_phase})"
        )

    # íŠ¸ë¦¬ê±° 2: ì‹œì¥ ì‹œê°„ ê¸°ë°˜ TTL ì´ˆê³¼
    ttl_hours = get_ttl_hours(market_phase)
    if staleness_hours >= ttl_hours:
        return True, (
            f"ì‹œì¥ ë‹¨ê³„ë³„ TTL ì´ˆê³¼ ({market_phase}: {staleness_hours:.1f}h > {ttl_hours}h)"
        )

    # íŠ¸ë¦¬ê±° 3: ì£¼ê°€ ê¸‰ë³€ (ì¥ì¤‘ë§Œ)
    if market_phase in ["market_open", "trading", "market_close"] and current_price:
        price_threshold = get_price_threshold(market_phase)
        price_change_rate = abs(current_price.get("change_rate", 0))

        if price_change_rate >= price_threshold:
            return True, (
                f"ì£¼ê°€ ê¸‰ë³€ ({price_change_rate:.1f}%, ì„ê³„ê°’: {price_threshold}%, "
                f"ì‹œì¥: {market_phase})"
            )

    # íŠ¸ë¦¬ê±° 4: ì˜ˆì¸¡ ë°©í–¥ ë³€í™”
    if predictions:
        current_up_ratio = sum(1 for p in predictions if p.direction == "up") / len(predictions)
        report_up_ratio = existing_summary.up_count / existing_summary.total_predictions if existing_summary.total_predictions > 0 else 0

        direction_threshold = get_direction_threshold(market_phase)
        direction_change = abs(current_up_ratio - report_up_ratio)

        if direction_change >= direction_threshold:
            return True, (
                f"ì˜ˆì¸¡ ë°©í–¥ ê¸‰ë³€ (ìƒìŠ¹ ë¹„ìœ¨: {report_up_ratio:.1%} â†’ {current_up_ratio:.1%}, "
                f"ë³€í™”: {direction_change:.1%}, ì„ê³„ê°’: {direction_threshold:.1%}, ì‹œì¥: {market_phase})"
            )

    return False, f"ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” (ì‹œì¥: {market_phase}, ê²½ê³¼: {staleness_hours:.1f}h/{ttl_hours}h)"


async def update_stock_analysis_summary(
    stock_code: str,
    db: Session,
    force_update: bool = False
) -> Optional[StockAnalysisSummary]:
    """
    ì¢…ëª© íˆ¬ì ë¶„ì„ ìš”ì•½ ì—…ë°ì´íŠ¸ (LLM ê¸°ë°˜)

    Args:
        stock_code: ì¢…ëª© ì½”ë“œ
        db: Database session
        force_update: ê°•ì œ ì—…ë°ì´íŠ¸ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)

    Returns:
        StockAnalysisSummary ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        # 1. ìµœê·¼ 30ì¼ ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ (ìµœëŒ€ 20ê±´)
        predictions = (
            db.query(Prediction)
            .filter(Prediction.stock_code == stock_code)
            .order_by(Prediction.created_at.desc())
            .limit(20)
            .all()
        )

        if not predictions:
            logger.warning(f"ì¢…ëª© {stock_code}ì— ëŒ€í•œ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # 2. í˜„ì¬ê°€ ì •ë³´ ì¡°íšŒ
        current_price_obj = (
            db.query(StockPrice)
            .filter(StockPrice.stock_code == stock_code)
            .order_by(StockPrice.date.desc())
            .first()
        )

        current_price = None
        if current_price_obj:
            # ì „ì¼ ëŒ€ë¹„ ë³€ë™ë¥  ê³„ì‚°
            previous_price_obj = (
                db.query(StockPrice)
                .filter(
                    StockPrice.stock_code == stock_code,
                    StockPrice.date < current_price_obj.date
                )
                .order_by(StockPrice.date.desc())
                .first()
            )

            change_rate = 0.0
            if previous_price_obj and previous_price_obj.close > 0:
                change_rate = ((current_price_obj.close - previous_price_obj.close) / previous_price_obj.close) * 100

            current_price = {
                "close": current_price_obj.close,
                "change_rate": round(change_rate, 2),
            }

        # 3. ê¸°ì¡´ ìš”ì•½ ì¡°íšŒ
        existing_summary = (
            db.query(StockAnalysisSummary)
            .filter(StockAnalysisSummary.stock_code == stock_code)
            .order_by(StockAnalysisSummary.last_updated.desc())
            .first()
        )

        # 4. ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ í™•ì¸ (ì‹œì¥ ì‹œê°„ ê¸°ë°˜ ë‹¤ì¤‘ íŠ¸ë¦¬ê±°)
        should_update, reason = await should_update_report(
            stock_code, db, existing_summary, predictions, current_price, force_update
        )

        if not should_update:
            logger.info(f"ì¢…ëª© {stock_code}ì˜ ë¶„ì„ ìš”ì•½ì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. ({reason})")
            return existing_summary

        logger.info(f"ì¢…ëª© {stock_code} ì—…ë°ì´íŠ¸ ì‹œì‘: {reason}")

        # 5. LLM ë¦¬í¬íŠ¸ ìƒì„± (ëª¨ë“  í™œì„± ëª¨ë¸ ëŒ€ìƒ)
        active_models: List[Model] = (
            db.query(Model).filter(Model.is_active == True).all()
        )

        if not active_models:
            logger.error("í™œì„±í™”ëœ LLM ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return None

        generator = get_report_generator()
        report_data = generator._prepare_report_data(
            stock_code, predictions, current_price
        )
        prompt = generator._build_prompt(report_data)

        total_predictions = len(predictions)
        up_count = sum(1 for p in predictions if p.direction == "up")
        down_count = sum(1 for p in predictions if p.direction == "down")
        hold_count = sum(1 for p in predictions if p.direction == "hold")
        confidences = [p.confidence for p in predictions if p.confidence]
        avg_confidence = sum(confidences) / len(confidences) if confidences else None

        created_summaries: List[StockAnalysisSummary] = []
        failed_models = []

        for model in active_models:
            try:
                logger.info(
                    f"ëª¨ë¸ {model.name} ({model.provider}/{model.model_identifier}) ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘"
                )
                report_payload = _generate_report_for_model(
                    generator=generator,
                    model=model,
                    prompt=prompt,
                )

                if not report_payload:
                    logger.warning(
                        f"âš ï¸ ëª¨ë¸ {model.name} ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ì‘ë‹µ): {stock_code}"
                    )
                    failed_models.append(model.name)
                    continue

                summary = _build_summary_from_payload(
                    stock_code=stock_code,
                    model=model,
                    report_payload=report_payload,
                    total_predictions=total_predictions,
                    up_count=up_count,
                    down_count=down_count,
                    hold_count=hold_count,
                    avg_confidence=avg_confidence,
                )
                db.add(summary)
                created_summaries.append(summary)
                logger.info(
                    f"  âœ… ëª¨ë¸ {model.name} ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ (stock={stock_code})"
                )
            except Exception as model_error:
                logger.error(
                    f"âŒ ëª¨ë¸ {model.name} ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {model_error}",
                    exc_info=True
                )
                failed_models.append(model.name)
                continue

        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¦¬í¬íŠ¸ ìœ ì§€ (ë¡¤ë°±í•˜ì§€ ì•ŠìŒ)
        if not created_summaries:
            logger.error(
                f"âŒ ëª¨ë“  ëª¨ë¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {stock_code} "
                f"(ì‹¤íŒ¨ ëª¨ë¸: {', '.join(failed_models)})"
            )
            # ê¸°ì¡´ ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ ìœ ì§€í•˜ê¸° ìœ„í•´ ë¡¤ë°±í•˜ì§€ ì•ŠìŒ
            db.rollback()
            # ê¸°ì¡´ ë¦¬í¬íŠ¸ ë°˜í™˜ (ìˆìœ¼ë©´)
            if existing_summary:
                logger.warning(
                    f"âš ï¸ ê¸°ì¡´ ë¦¬í¬íŠ¸ ìœ ì§€: {stock_code} "
                    f"(ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {existing_summary.last_updated})"
                )
                return existing_summary
            return None

        # DB ì»¤ë°‹ ì‹œë„ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        max_retries = 3
        for attempt in range(max_retries):
            try:
                db.commit()
                for summary in created_summaries:
                    db.refresh(summary)

                # ì¼ë¶€ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê²½ê³  ë¡œê·¸
                if failed_models:
                    logger.warning(
                        f"âš ï¸ ì¼ë¶€ ëª¨ë¸ ì‹¤íŒ¨ (ì„±ê³µ: {len(created_summaries)}/{len(active_models)}): "
                        f"{stock_code} (ì‹¤íŒ¨ ëª¨ë¸: {', '.join(failed_models)})"
                    )
                else:
                    logger.info(
                        f"âœ… ëª¨ë“  ëª¨ë¸ ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ ({len(created_summaries)}/{len(active_models)}): {stock_code}"
                    )

                return created_summaries[0]
            except Exception as commit_error:
                db.rollback()
                if attempt < max_retries - 1:
                    logger.warning(
                        f"âš ï¸ DB ì»¤ë°‹ ì‹¤íŒ¨ (ì¬ì‹œë„ {attempt + 1}/{max_retries}): {commit_error}"
                    )
                    # ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    import time
                    time.sleep(0.1 * (attempt + 1))
                else:
                    logger.error(
                        f"âŒ DB ì»¤ë°‹ ìµœì¢… ì‹¤íŒ¨ ({max_retries}íšŒ ì‹œë„): {commit_error}",
                        exc_info=True
                    )
                    # ê¸°ì¡´ ë¦¬í¬íŠ¸ ë°˜í™˜
                    if existing_summary:
                        logger.warning(
                            f"âš ï¸ ì»¤ë°‹ ì‹¤íŒ¨ë¡œ ê¸°ì¡´ ë¦¬í¬íŠ¸ ìœ ì§€: {stock_code}"
                        )
                        return existing_summary
                    return None

    except Exception as e:
        logger.error(f"ì¢…ëª© {stock_code}ì˜ ë¶„ì„ ìš”ì•½ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        db.rollback()
        return None


def get_stock_analysis_summary(
    stock_code: str,
    db: Session
) -> Optional[Dict[str, Any]]:
    """
    ì¢…ëª© íˆ¬ì ë¶„ì„ ìš”ì•½ ì¡°íšŒ

    Args:
        stock_code: ì¢…ëª© ì½”ë“œ
        db: Database session

    Returns:
        ë¶„ì„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
    """
    try:
        from backend.config import settings

        model_map = {
            model.id: model for model in db.query(Model).all()
        }

        ab_config: Optional[ABTestConfig] = None
        if settings.AB_TEST_ENABLED:
            ab_config = (
                db.query(ABTestConfig)
                .filter(ABTestConfig.is_active == True)
                .first()
            )

        if ab_config:
            report_a = _fetch_latest_summary(
                db, stock_code, model_id=ab_config.model_a_id
            )
            report_b = _fetch_latest_summary(
                db, stock_code, model_id=ab_config.model_b_id
            )

            if report_a and report_b:
                formatted_a = _format_summary_output(report_a, model_map)
                formatted_b = _format_summary_output(report_b, model_map)
                comparison = _build_comparison(formatted_a, formatted_b)
                meta_last_updated = max(
                    report_a.last_updated or datetime.min,
                    report_b.last_updated or datetime.min,
                )
                meta_prediction_count = max(
                    report_a.based_on_prediction_count or 0,
                    report_b.based_on_prediction_count or 0,
                )

                return {
                    "ab_test_enabled": True,
                    "model_a": formatted_a,
                    "model_b": formatted_b,
                    "comparison": comparison,
                    "meta": {
                        "last_updated": meta_last_updated.isoformat()
                        if meta_last_updated
                        else None,
                        "based_on_prediction_count": meta_prediction_count,
                    },
                }

        # A/B ë¹„í™œì„±í™” ë˜ëŠ” ëª¨ë¸ ë¦¬í¬íŠ¸ ë¯¸ì¡´ì¬ ì‹œ ìµœì‹  ë¦¬í¬íŠ¸ 1ê±´ ë°˜í™˜
        summary = _fetch_latest_summary(db, stock_code)

        if not summary:
            return None

        return _format_summary_output(summary, model_map)

    except Exception as e:
        logger.error(f"ì¢…ëª© {stock_code}ì˜ ë¶„ì„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        return None


def _generate_report_for_model(
    generator,
    model: Model,
    prompt: str,
) -> Optional[Dict[str, Any]]:
    """ì£¼ì–´ì§„ ëª¨ë¸ë¡œ LLM ë¦¬í¬íŠ¸ë¥¼ ìƒì„±."""
    try:
        client = generator._create_client(model.provider)
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
            },
            {"role": "user", "content": prompt},
        ]

        kwargs = {
            "model": model.model_identifier,
            "messages": messages,
            "temperature": 0.4,
            "max_tokens": 1000,
        }

        if model.provider != "openrouter":
            kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**kwargs)
        result_text = response.choices[0].message.content

        if model.provider == "openrouter":
            result_text = _extract_openrouter_json(result_text)

        return json.loads(result_text)
    except Exception as e:
        logger.error(
            f"ëª¨ë¸ {model.name} ({model.provider}) ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}",
            exc_info=True,
        )
        return None


def _build_summary_from_payload(
    stock_code: str,
    model: Model,
    report_payload: Dict[str, Any],
    total_predictions: int,
    up_count: int,
    down_count: int,
    hold_count: int,
    avg_confidence: Optional[float],
) -> StockAnalysisSummary:
    """LLM ì‘ë‹µì„ StockAnalysisSummary ì—”í‹°í‹°ë¡œ ë³€í™˜."""
    price_targets = report_payload.get("price_targets") or {}
    now = datetime.now()

    # JSON í•„ë“œëŠ” ì§ë ¬í™”ëœ ë¬¸ìì—´ë¡œ ì €ì¥
    risk_factors = report_payload.get("risk_factors", [])
    opportunity_factors = report_payload.get("opportunity_factors", [])

    return StockAnalysisSummary(
        stock_code=stock_code,
        model_id=model.id,
        overall_summary=report_payload.get("overall_summary"),
        short_term_scenario=report_payload.get("short_term_scenario"),
        medium_term_scenario=report_payload.get("medium_term_scenario"),
        long_term_scenario=report_payload.get("long_term_scenario"),
        risk_factors=json.dumps(risk_factors) if isinstance(risk_factors, list) else risk_factors,
        opportunity_factors=json.dumps(opportunity_factors) if isinstance(opportunity_factors, list) else opportunity_factors,
        recommendation=report_payload.get("recommendation"),
        custom_data=json.dumps({
            "model_id": model.id,
            "model_name": model.name,
            "raw_report": report_payload,
        }),
        total_predictions=total_predictions,
        up_count=up_count,
        down_count=down_count,
        hold_count=hold_count,
        avg_confidence=avg_confidence,
        base_price=price_targets.get("base_price"),
        short_term_target_price=price_targets.get("short_term_target"),
        short_term_support_price=price_targets.get("short_term_support"),
        medium_term_target_price=price_targets.get("medium_term_target"),
        medium_term_support_price=price_targets.get("medium_term_support"),
        long_term_target_price=price_targets.get("long_term_target"),
        last_updated=now,
        based_on_prediction_count=total_predictions,
    )


def _extract_openrouter_json(text: str) -> str:
    """OpenRouter ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ."""
    json_match = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
    if json_match:
        return json_match.group(1)

    json_match = re.search(r"```\s*(\{.*?\})\s*```", text, re.DOTALL)
    if json_match:
        return json_match.group(1)

    json_match = re.search(r"(\{[^{]*\"overall_summary\".*\})\s*$", text, re.DOTALL)
    if json_match:
        return json_match.group(1)

    return text


def _fetch_latest_summary(
    db: Session,
    stock_code: str,
    model_id: Optional[int] = None,
) -> Optional[StockAnalysisSummary]:
    """íŠ¹ì • ì¢…ëª©(+ëª¨ë¸)ì˜ ìµœì‹  ë¦¬í¬íŠ¸ ì¡°íšŒ."""
    query = db.query(StockAnalysisSummary).filter(
        StockAnalysisSummary.stock_code == stock_code
    )
    if model_id is not None:
        query = query.filter(StockAnalysisSummary.model_id == model_id)

    return query.order_by(StockAnalysisSummary.last_updated.desc()).first()


def _format_summary_output(
    summary: StockAnalysisSummary,
    model_map: Dict[int, Model],
) -> Dict[str, Any]:
    """StockAnalysisSummary ì—”í‹°í‹°ë¥¼ API ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜."""
    model_info = model_map.get(summary.model_id) if summary.model_id else None
    statistics = {
        "total_predictions": summary.total_predictions,
        "up_count": summary.up_count,
        "down_count": summary.down_count,
        "hold_count": summary.hold_count,
        "avg_confidence": round(summary.avg_confidence * 100, 1)
        if summary.avg_confidence
        else None,
    }
    price_targets = {
        "base_price": summary.base_price,
        "short_term_target": summary.short_term_target_price,
        "short_term_support": summary.short_term_support_price,
        "medium_term_target": summary.medium_term_target_price,
        "medium_term_support": summary.medium_term_support_price,
        "long_term_target": summary.long_term_target_price,
    }

    # JSON ë¬¸ìì—´ íŒŒì‹±
    risk_factors = summary.risk_factors
    if isinstance(risk_factors, str):
        try:
            risk_factors = json.loads(risk_factors)
        except:
            risk_factors = []
    elif risk_factors is None:
        risk_factors = []

    opportunity_factors = summary.opportunity_factors
    if isinstance(opportunity_factors, str):
        try:
            opportunity_factors = json.loads(opportunity_factors)
        except:
            opportunity_factors = []
    elif opportunity_factors is None:
        opportunity_factors = []

    return {
        "model_id": summary.model_id,
        "model_name": model_info.name if model_info else None,
        "overall_summary": summary.overall_summary,
        "short_term_scenario": summary.short_term_scenario,
        "medium_term_scenario": summary.medium_term_scenario,
        "long_term_scenario": summary.long_term_scenario,
        "risk_factors": risk_factors,
        "opportunity_factors": opportunity_factors,
        "recommendation": summary.recommendation,
        "price_targets": price_targets,
        "statistics": statistics,
        "meta": {
            "last_updated": summary.last_updated.isoformat()
            if summary.last_updated
            else None,
            "based_on_prediction_count": summary.based_on_prediction_count,
        },
    }


def _build_comparison(
    report_a: Dict[str, Any],
    report_b: Dict[str, Any],
) -> Dict[str, Any]:
    """ë‘ ë¦¬í¬íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ê³µí†µì  ë„ì¶œ."""
    rec_a = (report_a.get("recommendation") or "").lower()
    rec_b = (report_b.get("recommendation") or "").lower()

    recommendation_match = False
    if ("ë§¤ìˆ˜" in rec_a and "ë§¤ìˆ˜" in rec_b) or \
       ("ë§¤ë„" in rec_a and "ë§¤ë„" in rec_b) or \
       ("ê´€ë§" in rec_a and "ê´€ë§" in rec_b) or \
       ("ë³´ìœ " in rec_a and "ë³´ìœ " in rec_b):
        recommendation_match = True

    risks_a = set(report_a.get("risk_factors") or [])
    risks_b = set(report_b.get("risk_factors") or [])
    opps_a = set(report_a.get("opportunity_factors") or [])
    opps_b = set(report_b.get("opportunity_factors") or [])

    return {
        "recommendation_match": recommendation_match,
        "risk_overlap": list(risks_a & risks_b),
        "opportunity_overlap": list(opps_a & opps_b),
    }
