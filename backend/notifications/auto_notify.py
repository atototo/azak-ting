"""
ìë™ ì•Œë¦¼ ëª¨ë“ˆ

ìƒˆë¡œìš´ ë‰´ìŠ¤ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
"""
import logging
from datetime import datetime, timedelta
from typing import List
from sqlalchemy.orm import Session

from backend.db.models.news import NewsArticle
from backend.llm.vector_search import get_vector_search
from backend.llm.predictor import get_predictor
from backend.notifications.telegram import get_telegram_notifier
from backend.utils.embedding_deduplicator import get_embedding_deduplicator
from backend.config import settings


logger = logging.getLogger(__name__)


async def process_new_news_notifications(
    db: Session,
    lookback_minutes: int = 15,
) -> dict:
    """
    ìµœê·¼ì— ì €ì¥ëœ ë‰´ìŠ¤ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.

    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        lookback_minutes: ì¡°íšŒí•  ê³¼ê±° ì‹œê°„ (ë¶„ ë‹¨ìœ„)

    Returns:
        ì²˜ë¦¬ í†µê³„ {processed, success, failed}
    """
    try:
        # ì˜¤ëŠ˜ 0ì‹œ ì´í›„ì˜ ë‰´ìŠ¤ ì¡°íšŒ (ëˆ„ë½ ë°©ì§€)
        # 15ë¶„ lookback ëŒ€ì‹  í•˜ë£¨ ì „ì²´ë¥¼ ì¡°íšŒí•˜ì—¬ ìŠ¤ì¼€ì¤„ëŸ¬ ëˆ„ë½ ì‹œì—ë„ ë³µêµ¬ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        today_start = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
        cutoff_time = today_start

        recent_news = (
            db.query(NewsArticle)
            .filter(
                NewsArticle.created_at >= cutoff_time,
                NewsArticle.stock_code.isnot(None),
                NewsArticle.predicted_at.is_(None),  # ì•„ì§ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì€ ë‰´ìŠ¤ë§Œ
            )
            .order_by(NewsArticle.created_at.desc())
            .limit(20)  # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ (20ê±´ -> 30ì´ˆ/ê±´ -> 10ë¶„)
            .all()
        )

        if not recent_news:
            logger.debug(f"ìµœê·¼ {lookback_minutes}ë¶„ ì´ë‚´ ìƒˆ ë‰´ìŠ¤ ì—†ìŒ")
            return {"processed": 0, "success": 0, "failed": 0}

        logger.info(
            f"ğŸ”” ìë™ ì•Œë¦¼ ì²˜ë¦¬: ìµœê·¼ {lookback_minutes}ë¶„ ì´ë‚´ {len(recent_news)}ê±´ ë°œê²¬"
        )

        vector_search = await get_vector_search()
        predictor = get_predictor()
        notifier = get_telegram_notifier()
        embedding_deduplicator = get_embedding_deduplicator()

        success_count = 0
        failed_count = 0
        skipped_count = 0

        for news in recent_news:
            try:
                logger.info(f"ì²˜ë¦¬ ì¤‘: {news.title[:50]}... (ì¢…ëª©: {news.stock_code})")

                # 0. ì„ë² ë”© ê¸°ë°˜ ì•Œë¦¼ ì¤‘ë³µ ê²€ì‚¬
                news_text = f"{news.title}\n{news.content}"
                should_skip, similar_id, similarity = await embedding_deduplicator.should_skip_notification(
                    news_text=news_text,
                    stock_code=news.stock_code,
                    db=db,
                    notification_lookback_hours=4,
                )

                if should_skip:
                    logger.info(
                        f"ğŸ”• ìœ ì‚¬ ë‰´ìŠ¤ ì•Œë¦¼ ì´ë ¥ ì¡´ì¬ (ìœ ì‚¬ë„={similarity:.3f}) "
                        f"â†’ ì•Œë¦¼ skip (ë‰´ìŠ¤ ID={news.id}, ìœ ì‚¬ ë‰´ìŠ¤ ID={similar_id})"
                    )
                    # notified_at, predicted_at ì—…ë°ì´íŠ¸ (ì•Œë¦¼ skipí–ˆì§€ë§Œ ì²˜ë¦¬ëŠ” ì™„ë£Œ)
                    news.predicted_at = datetime.utcnow()
                    news.notified_at = datetime.utcnow()
                    db.commit()
                    skipped_count += 1
                    continue

                # 1. ìœ ì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰
                similar_news = await vector_search.get_news_with_price_changes(
                    news_text=news_text,
                    stock_code=news.stock_code,
                    db=db,
                    top_k=5,
                    similarity_threshold=0.5,
                )

                # 2. ì˜ˆì¸¡ ìˆ˜í–‰
                current_news_data = {
                    "title": news.title,
                    "content": news.content,
                    "stock_code": news.stock_code,
                }

                # ë©€í‹°ëª¨ë¸ ì˜ˆì¸¡: ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìƒì„±
                all_predictions = predictor.predict_all_models(
                    current_news=current_news_data,
                    similar_news=similar_news,
                    news_id=news.id,
                )

                # A/B ì„¤ì •ì— ë”°ë¼ í‘œì‹œí•  ë‘ ëª¨ë¸ ì˜ˆì¸¡ ì¡°íšŒ
                prediction = predictor.get_ab_predictions(news_id=news.id)

                # ì˜ˆì¸¡ ì™„ë£Œ ì‹œê° ê¸°ë¡ (ì•Œë¦¼ ì„±ê³µ ì—¬ë¶€ì™€ ë¬´ê´€)
                news.predicted_at = datetime.utcnow()
                db.commit()

                # 3. í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (ì„ì‹œ ë¹„í™œì„±í™”)
                # TODO: í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì¬í™œì„±í™” ì‹œ ì£¼ì„ í•´ì œ
                # if notifier.send_prediction(
                #     news_title=news.title,
                #     stock_code=news.stock_code,
                #     prediction=prediction,
                # ):
                #     # ì•Œë¦¼ ì „ì†¡ ì„±ê³µ ì‹œ notified_at ì—…ë°ì´íŠ¸
                #     news.notified_at = datetime.utcnow()
                #     db.commit()
                #
                #     success_count += 1
                #     comp = prediction.get("comparison", {})
                #     logger.info(
                #         f"âœ… A/B ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {news.title[:30]}... "
                #         f"(ëª¨ë¸ {len(all_predictions)}ê°œ ì˜ˆì¸¡ ì™„ë£Œ, A/B ì¼ì¹˜: {comp.get('agreement')}, ì°¨ì´: {comp.get('confidence_diff')}%)"
                #     )
                # else:
                #     failed_count += 1
                #     logger.warning(f"âš ï¸  ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {news.title[:30]}...")

                # ì•Œë¦¼ ì „ì†¡ ì—†ì´ ì˜ˆì¸¡ë§Œ ì™„ë£Œ
                success_count += 1
                logger.info(
                    f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {news.title[:30]}... (ëª¨ë¸ {len(all_predictions)}ê°œ)"
                )

            except Exception as e:
                failed_count += 1
                logger.error(f"âŒ ë‰´ìŠ¤ ì²˜ë¦¬ ì‹¤íŒ¨ (ID={news.id}): {e}", exc_info=True)

        logger.info(
            f"ğŸ“Š ìë™ ì•Œë¦¼ ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {failed_count}ê±´, skip {skipped_count}ê±´"
        )

        return {
            "processed": len(recent_news),
            "success": success_count,
            "failed": failed_count,
            "skipped": skipped_count,
        }

    except Exception as e:
        logger.error(f"âŒ ìë™ ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"processed": 0, "success": 0, "failed": 0}
