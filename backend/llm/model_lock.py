"""
PyTorch/FAISS ëª¨ë¸ ë¡œë“œ ì‹œ ë™ì‹œì„± ì œì–´

AsyncIOScheduler í™˜ê²½ì—ì„œ ì—¬ëŸ¬ ì‘ì—…ì´ ë™ì‹œì— PyTorch ëª¨ë¸ì„ ë¡œë“œí•˜ë©´
Segmentation Faultê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ Lockì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…ë§Œ PyTorch ëª¨ë¸ì— ì ‘ê·¼í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.
"""
import asyncio
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class ModelLoadLock:
    """
    PyTorch/FAISS ëª¨ë¸ ë¡œë“œ ì‹œ ë™ì‹œ ì ‘ê·¼ ë°©ì§€ (Singleton)

    Usage:
        from backend.llm.model_lock import ModelLoadLock

        async with ModelLoadLock.get_lock():
            # PyTorch ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ì‚¬ìš©
            model.load()
    """
    _lock: Optional[asyncio.Lock] = None

    @classmethod
    def get_lock(cls) -> asyncio.Lock:
        """
        ì „ì—­ Lock ë°˜í™˜ (Singleton)

        Returns:
            asyncio.Lock: ëª¨ë“  ì‘ì—…ì´ ê³µìœ í•˜ëŠ” ë‹¨ì¼ Lock
        """
        if cls._lock is None:
            cls._lock = asyncio.Lock()
            logger.info("ğŸ”’ ModelLoadLock ì´ˆê¸°í™” ì™„ë£Œ (PyTorch ë™ì‹œì„± ì œì–´)")
        return cls._lock
